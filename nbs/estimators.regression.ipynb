{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9982e62d",
   "metadata": {},
   "source": [
    "# Regressor\n",
    "\n",
    "> `PoniardRegressor` inherits from `PoniardBaseEstimator`, which sets up most of the funcionality, so you should probably read the [those docs](estimators.core.ipynb) first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d952ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp estimators.regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89247208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d021a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from typing import List, Optional, Union, Callable, Dict, Any, Sequence\n",
    "\n",
    "from sklearn.base import RegressorMixin, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection._split import BaseCrossValidator, BaseShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    HistGradientBoostingRegressor,\n",
    ")\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from poniard.estimators.core import PoniardBaseEstimator\n",
    "from poniard.plot.plot_factory import PoniardPlotFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6cf092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class PoniardRegressor(PoniardBaseEstimator):\n",
    "    \"\"\"Cross validate multiple regressors, rank them, fine tune them and ensemble them.\n",
    "\n",
    "    PoniardRegressor takes a list/dict of scikit-learn estimators and compares their performance\n",
    "    on a list/dict of scikit-learn metrics using a predefined scikit-learn cross-validation\n",
    "    strategy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimators :\n",
    "        Estimators to evaluate.\n",
    "    metrics :\n",
    "        Metrics to compute for each estimator. This is more restrictive than sklearn's scoring\n",
    "        parameter, as it does not allow callable scorers. Single strings are cast to lists\n",
    "        automatically.\n",
    "    preprocess : bool, optional\n",
    "        If True, impute missing values, standard scale numeric data and one-hot or ordinal\n",
    "        encode categorical data.\n",
    "    scaler :\n",
    "        Numeric scaler method. Either \"standard\", \"minmax\", \"robust\" or scikit-learn Transformer.\n",
    "    high_cardinality_encoder :\n",
    "        Encoder for categorical features with high cardinality. Either \"target\" or \"ordinal\",\n",
    "        or scikit-learn Transformer.\n",
    "    numeric_imputer :\n",
    "        Imputation method. Either \"simple\", \"iterative\" or scikit-learn Transformer.\n",
    "    custom_preprocessor :\n",
    "        Preprocessor used instead of the default preprocessing pipeline. It must be able to be\n",
    "        included directly in a scikit-learn Pipeline.\n",
    "    numeric_threshold :\n",
    "        Number features with unique values above a certain threshold will be treated as numeric. If\n",
    "        float, the threshold is `numeric_threshold * samples`.\n",
    "    cardinality_threshold :\n",
    "        Non-number features with cardinality above a certain threshold will be treated as\n",
    "        ordinal encoded instead of one-hot encoded. If float, the threshold is\n",
    "        `cardinality_threshold * samples`.\n",
    "    cv :\n",
    "        Cross validation strategy. Either an integer, a scikit-learn cross validation object,\n",
    "        or an iterable.\n",
    "    verbose :\n",
    "        Verbosity level. Propagated to every scikit-learn function and estimator.\n",
    "    random_state :\n",
    "        RNG. Propagated to every scikit-learn function and estimator. The default None sets\n",
    "        random_state to 0 so that cross_validate results are comparable.\n",
    "    n_jobs :\n",
    "        Controls parallel processing. -1 uses all cores. Propagated to every scikit-learn\n",
    "        function and estimator.\n",
    "    plugins :\n",
    "        Plugin instances that run in set moments of setup, fit and plotting.\n",
    "    plot_options :\n",
    "        :class:poniard.plot.plot_factory.PoniardPlotFactory instance specifying Plotly format\n",
    "        options or None, which sets the default factory.\n",
    "    cache_transformations :\n",
    "        Whether to cache transformations and set the `memory` parameter for Pipelines. This can\n",
    "        speed up slow transformations as they are not recalculated for each estimator.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimators: Optional[\n",
    "            Union[Dict[str, RegressorMixin], Sequence[RegressorMixin]]\n",
    "        ] = None,\n",
    "        metrics: Optional[Union[str, Dict[str, Callable], Sequence[str]]] = None,\n",
    "        preprocess: bool = True,\n",
    "        scaler: Optional[Union[str, TransformerMixin]] = None,\n",
    "        high_cardinality_encoder: Optional[Union[str, TransformerMixin]] = None,\n",
    "        numeric_imputer: Optional[Union[str, TransformerMixin]] = None,\n",
    "        custom_preprocessor: Union[None, Pipeline, TransformerMixin] = None,\n",
    "        numeric_threshold: Union[int, float] = 0.1,\n",
    "        cardinality_threshold: Union[int, float] = 20,\n",
    "        cv: Union[int, BaseCrossValidator, BaseShuffleSplit, Sequence] = None,\n",
    "        verbose: int = 0,\n",
    "        random_state: Optional[int] = None,\n",
    "        n_jobs: Optional[int] = None,\n",
    "        plugins: Optional[Sequence[Any]] = None,\n",
    "        plot_options: Optional[PoniardPlotFactory] = None,\n",
    "        cache_transformations: bool = False,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            estimators=estimators,\n",
    "            metrics=metrics,\n",
    "            preprocess=preprocess,\n",
    "            scaler=scaler,\n",
    "            high_cardinality_encoder=high_cardinality_encoder,\n",
    "            numeric_imputer=numeric_imputer,\n",
    "            custom_preprocessor=custom_preprocessor,\n",
    "            numeric_threshold=numeric_threshold,\n",
    "            cardinality_threshold=cardinality_threshold,\n",
    "            cv=cv,\n",
    "            verbose=verbose,\n",
    "            random_state=random_state,\n",
    "            n_jobs=n_jobs,\n",
    "            plugins=plugins,\n",
    "            plot_options=plot_options,\n",
    "            cache_transformations=cache_transformations,\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def _default_estimators(self) -> List[RegressorMixin]:\n",
    "        return [\n",
    "            LinearRegression(),\n",
    "            ElasticNet(random_state=self.random_state),\n",
    "            LinearSVR(\n",
    "                verbose=self.verbose, random_state=self.random_state, max_iter=5000\n",
    "            ),\n",
    "            KNeighborsRegressor(),\n",
    "            DecisionTreeRegressor(random_state=self.random_state),\n",
    "            RandomForestRegressor(\n",
    "                random_state=self.random_state, verbose=self.verbose, n_jobs=self.n_jobs\n",
    "            ),\n",
    "            HistGradientBoostingRegressor(\n",
    "                random_state=self.random_state, verbose=self.verbose\n",
    "            ),\n",
    "            XGBRegressor(random_state=self.random_state),\n",
    "        ]\n",
    "\n",
    "    def _build_metrics(self) -> Union[Dict[str, Callable], List[str], Callable]:\n",
    "        return [\n",
    "            \"neg_mean_squared_error\",\n",
    "            \"neg_mean_absolute_percentage_error\",\n",
    "            \"neg_median_absolute_error\",\n",
    "            \"r2\",\n",
    "        ]\n",
    "\n",
    "    def _build_cv(self) -> BaseCrossValidator:\n",
    "        cv = self.cv or 5\n",
    "        if isinstance(cv, int):\n",
    "            return KFold(n_splits=cv, shuffle=True, random_state=self.random_state)\n",
    "        else:\n",
    "            self._pass_instance_attrs(cv)\n",
    "            return cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48f2e09",
   "metadata": {},
   "source": [
    "`PoniardRegressor` implements `PoniardClassifier._build_cv`, `PoniardClassifier._build_metrics` and `PoniardClassifier._default_estimators`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e56680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### PoniardRegressor._build_cv\n",
       "\n",
       ">      PoniardRegressor._build_cv ()"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### PoniardRegressor._build_cv\n",
       "\n",
       ">      PoniardRegressor._build_cv ()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(PoniardRegressor._build_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c35a7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### PoniardRegressor._build_metrics\n",
       "\n",
       ">      PoniardRegressor._build_metrics ()\n",
       "\n",
       "Build metrics."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### PoniardRegressor._build_metrics\n",
       "\n",
       ">      PoniardRegressor._build_metrics ()\n",
       "\n",
       "Build metrics."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(PoniardRegressor._build_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2800d688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### PoniardRegressor._default_estimators\n",
       "\n",
       ">      PoniardRegressor._default_estimators ()"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### PoniardRegressor._default_estimators\n",
       "\n",
       ">      PoniardRegressor._default_estimators ()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(PoniardRegressor._default_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7026846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poniard",
   "language": "python",
   "name": "poniard"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
