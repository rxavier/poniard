{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/rxavier/poniard/main/logo.png\" alt=\"Poniard logo\" title=\"Poniard\" width=\"50%\"/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poniard\n",
    "\n",
    "> Streamline scikit-learn model comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "> A poniard /ˈpɒnjərd/ or poignard (Fr.) is a long, lightweight thrusting knife ([Wikipedia](https://en.wikipedia.org/wiki/Poignard)).\n",
    "\n",
    "Poniard is a scikit-learn companion library that streamlines the process of fitting different machine learning models and comparing them. \n",
    "\n",
    "It can be used to provide quick answers to questions like these:\n",
    "* What is the reasonable range of scores for this task?\n",
    "* Is a simple and explainable linear model enough or should I work with forests and gradient boosters?\n",
    "* Are the features good enough as is or should I work on feature engineering?\n",
    "* How much can hyperparemeter tuning improve metrics?\n",
    "* Do I need to work on a custom preprocessing strategy?\n",
    "\n",
    "This is not meant to be end to end solution, and you definitely should keep on working on your models after you are done with Poniard.\n",
    "\n",
    "The core functionality has been tested to work on Python 3.7 through 3.10 on Linux systems, and from\n",
    "3.8 to 3.10 on macOS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Stable version:\n",
    "\n",
    "```bash\n",
    "pip install poniard\n",
    "```\n",
    "\n",
    "Dev version with most up to date changes:\n",
    "\n",
    "```bash\n",
    "pip install git+https://github.com/rxavier/poniard.git@develop#egg=poniard\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "Check the full [Quarto docs](https://rxavier.github.io/poniard), including guides and API reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage/features\n",
    "\n",
    "### Basics\n",
    "The API was designed with tabular tasks in mind, but it should also work with time series tasks provided an appropiate cross validation strategy is used (don't shuffle!)\n",
    "\n",
    "The usual Poniard flow is:\n",
    "1. Define some estimators.\n",
    "2. Define some metrics.\n",
    "3. Define a cross validation strategy.\n",
    "4. Fit everything.\n",
    "5. Print the results.\n",
    "\n",
    "Poniard provides sane defaults for 1, 2 and 3, so in most cases you can just do...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poniard import PoniardRegressor\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                         <h2>Setup info</h2>\n",
       "                         <h3>Target</h3>\n",
       "                             <p><b>Type:</b> continuous</p>\n",
       "                             <p><b>Shape:</b> (442,)</p>\n",
       "                             <p><b>Unique values:</b> 214</p>\n",
       "                             <h3>Metrics</h3>\n",
       "                             <b>Main metric:</b> neg_mean_squared_error\n",
       "                             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " <h3>Feature type inference</h3>\n",
       "                                <p><b>Minimum unique values to consider a number-like feature numeric:</b> 44</p>\n",
       "                                <p><b>Minimum unique values to consider a categorical feature high cardinality:</b> 20</p>\n",
       "                                <p><b>Inferred feature types:</b></p>\n",
       "                                <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numeric</th>\n",
       "      <th>categorical_high</th>\n",
       "      <th>categorical_low</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td></td>\n",
       "      <td>sex</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bmi</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bp</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>s4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>s5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>s6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PoniardRegressor(random_state=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_diabetes(return_X_y=True, as_frame=True)\n",
    "pnd = PoniardRegressor(random_state=0)\n",
    "pnd.setup(X, y)\n",
    "pnd.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and get a nice table showing the average of each metric in all folds for every model, including fit and score times (thanks, scikit-learn `cross_validate` function!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_neg_mean_absolute_percentage_error</th>\n",
       "      <th>test_neg_median_absolute_error</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>-2977.598515</td>\n",
       "      <td>-0.396566</td>\n",
       "      <td>-39.009146</td>\n",
       "      <td>0.489155</td>\n",
       "      <td>0.005265</td>\n",
       "      <td>0.001960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>-3159.017211</td>\n",
       "      <td>-0.422912</td>\n",
       "      <td>-42.619546</td>\n",
       "      <td>0.460740</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.001755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>-3431.823331</td>\n",
       "      <td>-0.419956</td>\n",
       "      <td>-42.203000</td>\n",
       "      <td>0.414595</td>\n",
       "      <td>0.101435</td>\n",
       "      <td>0.004821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <td>-3544.069433</td>\n",
       "      <td>-0.407417</td>\n",
       "      <td>-40.396390</td>\n",
       "      <td>0.391633</td>\n",
       "      <td>0.334695</td>\n",
       "      <td>0.009266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>-3615.195398</td>\n",
       "      <td>-0.418674</td>\n",
       "      <td>-38.980000</td>\n",
       "      <td>0.379625</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>0.002083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>-3923.488860</td>\n",
       "      <td>-0.426471</td>\n",
       "      <td>-39.031309</td>\n",
       "      <td>0.329961</td>\n",
       "      <td>0.055696</td>\n",
       "      <td>0.002855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>-4268.314411</td>\n",
       "      <td>-0.374296</td>\n",
       "      <td>-43.388592</td>\n",
       "      <td>0.271443</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>0.001721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyRegressor</th>\n",
       "      <td>-5934.577616</td>\n",
       "      <td>-0.621540</td>\n",
       "      <td>-61.775921</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>0.001627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>-6728.423034</td>\n",
       "      <td>-0.591906</td>\n",
       "      <td>-59.700000</td>\n",
       "      <td>-0.145460</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               test_neg_mean_squared_error  \\\n",
       "LinearRegression                              -2977.598515   \n",
       "ElasticNet                                    -3159.017211   \n",
       "RandomForestRegressor                         -3431.823331   \n",
       "HistGradientBoostingRegressor                 -3544.069433   \n",
       "KNeighborsRegressor                           -3615.195398   \n",
       "XGBRegressor                                  -3923.488860   \n",
       "LinearSVR                                     -4268.314411   \n",
       "DummyRegressor                                -5934.577616   \n",
       "DecisionTreeRegressor                         -6728.423034   \n",
       "\n",
       "                               test_neg_mean_absolute_percentage_error  \\\n",
       "LinearRegression                                             -0.396566   \n",
       "ElasticNet                                                   -0.422912   \n",
       "RandomForestRegressor                                        -0.419956   \n",
       "HistGradientBoostingRegressor                                -0.407417   \n",
       "KNeighborsRegressor                                          -0.418674   \n",
       "XGBRegressor                                                 -0.426471   \n",
       "LinearSVR                                                    -0.374296   \n",
       "DummyRegressor                                               -0.621540   \n",
       "DecisionTreeRegressor                                        -0.591906   \n",
       "\n",
       "                               test_neg_median_absolute_error   test_r2  \\\n",
       "LinearRegression                                   -39.009146  0.489155   \n",
       "ElasticNet                                         -42.619546  0.460740   \n",
       "RandomForestRegressor                              -42.203000  0.414595   \n",
       "HistGradientBoostingRegressor                      -40.396390  0.391633   \n",
       "KNeighborsRegressor                                -38.980000  0.379625   \n",
       "XGBRegressor                                       -39.031309  0.329961   \n",
       "LinearSVR                                          -43.388592  0.271443   \n",
       "DummyRegressor                                     -61.775921 -0.000797   \n",
       "DecisionTreeRegressor                              -59.700000 -0.145460   \n",
       "\n",
       "                               fit_time  score_time  \n",
       "LinearRegression               0.005265    0.001960  \n",
       "ElasticNet                     0.003509    0.001755  \n",
       "RandomForestRegressor          0.101435    0.004821  \n",
       "HistGradientBoostingRegressor  0.334695    0.009266  \n",
       "KNeighborsRegressor            0.003038    0.002083  \n",
       "XGBRegressor                   0.055696    0.002855  \n",
       "LinearSVR                      0.003470    0.001721  \n",
       "DummyRegressor                 0.003010    0.001627  \n",
       "DecisionTreeRegressor          0.004179    0.001667  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# |output: false\n",
    "\n",
    "pnd.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_neg_mean_absolute_percentage_error</th>\n",
       "      <th>test_neg_median_absolute_error</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>-2977.598515</td>\n",
       "      <td>-0.396566</td>\n",
       "      <td>-39.009146</td>\n",
       "      <td>0.489155</td>\n",
       "      <td>0.005265</td>\n",
       "      <td>0.001960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>-3159.017211</td>\n",
       "      <td>-0.422912</td>\n",
       "      <td>-42.619546</td>\n",
       "      <td>0.460740</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.001755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>-3431.823331</td>\n",
       "      <td>-0.419956</td>\n",
       "      <td>-42.203000</td>\n",
       "      <td>0.414595</td>\n",
       "      <td>0.101435</td>\n",
       "      <td>0.004821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <td>-3544.069433</td>\n",
       "      <td>-0.407417</td>\n",
       "      <td>-40.396390</td>\n",
       "      <td>0.391633</td>\n",
       "      <td>0.334695</td>\n",
       "      <td>0.009266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>-3615.195398</td>\n",
       "      <td>-0.418674</td>\n",
       "      <td>-38.980000</td>\n",
       "      <td>0.379625</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>0.002083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>-3923.488860</td>\n",
       "      <td>-0.426471</td>\n",
       "      <td>-39.031309</td>\n",
       "      <td>0.329961</td>\n",
       "      <td>0.055696</td>\n",
       "      <td>0.002855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>-4268.314411</td>\n",
       "      <td>-0.374296</td>\n",
       "      <td>-43.388592</td>\n",
       "      <td>0.271443</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>0.001721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyRegressor</th>\n",
       "      <td>-5934.577616</td>\n",
       "      <td>-0.621540</td>\n",
       "      <td>-61.775921</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>0.001627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>-6728.423034</td>\n",
       "      <td>-0.591906</td>\n",
       "      <td>-59.700000</td>\n",
       "      <td>-0.145460</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# |echo: false\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "res = pnd.get_results()\n",
    "display(HTML(res.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can also get a nice plot of your different metrics by using the `PoniardBaseEstimator.plot.metrics` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type inference\n",
    "Poniard uses some basic heuristics to infer the data types.\n",
    "\n",
    "Float and integer columns are defined as numeric if the number of unique values is greater than indicated by the `categorical_threshold` parameter.\n",
    "\n",
    "String/object/categorical columns are assumed to be categorical.\n",
    "\n",
    "Datetime features are processed separately with a custom encoder.\n",
    "\n",
    "For categorical features, high and low cardinality is defined by the `cardinality_threshold` parameter. Only low cardinality categorical features are one-hot encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembles\n",
    "Poniard makes it easy to combine various estimators in stacking or voting ensembles. The base esimators can be selected according to their performance (top-n) or chosen by their names.\n",
    "\n",
    "Poniard also reports how similar the predictions of the estimators are, so ensembles with different base estimators can be built. A basic correlation table of the cross-validated predictions is built for regression tasks, while [Cramér's V](https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V) is used for classification.\n",
    "\n",
    "By default, it computes this similarity of prediction errors instead of the actual predictions; this helps in building ensembles with good scoring estimators and uncorrelated errors, which in principle and hopefully should lead to a \"wisdom of crowds\" kind of situation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization\n",
    "The `PoniardBaseEstimator.tune_estimator` method can be used to optimize the hyperparameters of a given estimator, either by passing a grid of parameters or using the inbuilt ones available for default estimators. The tuned estimator will be added to the list of estimators and will be scored the next time `PoniardBaseEstimator.fit` is called."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "\n",
    "The `plot` accessor provides several plotting methods based on the attached Poniard estimator instance. These Plotly plots are based on a default template, but can be modified by passing a different `PoniardPlotFactory` to the Poniard `plot_options` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plugin system\n",
    "\n",
    "The `plugins` argument in Poniard estimators takes a plugin or list of plugins that subclass `BasePlugin`. These plugins have access to the Poniard estimator instance and hook onto different sections of the process, for example, on setup start, on fit end, on remove estimator, etc.\n",
    "\n",
    "This makes it easy for third parties to extend Poniard's functionality.\n",
    "\n",
    "Two plugins are baked into Poniard.\n",
    "1. Weights and Biases: logs your data, plots, runs wandb scikit-learn analysis, saves model artifacts, etc.\n",
    "2. Pandas Profiling: generates an HTML report of the features and target. If the Weights and Biases plugin is present, also logs this report to the wandb run.\n",
    "\n",
    "The requirements for these plugins are not included in the base Poniard dependencies, so you can safely ignore them if you don't intend to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design philosophy\n",
    "\n",
    "### Not another dependency\n",
    "We try very hard to avoid cluttering the environment with stuff you won't use outside of this library. Poniard's dependencies are:\n",
    "\n",
    "1. scikit-learn (duh)\n",
    "2. pandas\n",
    "3. XGBoost\n",
    "4. Plotly\n",
    "5. tqdm\n",
    "6. That's it!\n",
    "\n",
    "Apart from `tqdm` and possibly `Plotly`, all dependencies most likely were going to be installed anyway, so Poniard's added footprint should be small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We don't do that here (AutoML)\n",
    "Poniard tries not to take control away from the user. As such, it is not designed to perform 2 hours of feature engineering and selection, try every model under the sun together with endless ensembles and select the top performing model according to some metric.\n",
    "\n",
    "Instead, it strives to abstract away some of the boilerplate code needed to fit and compare a number of models and allows the user to decide what to do with the results.\n",
    "\n",
    "Poniard can be your first stab at a prediction problem, but it definitely shouldn't be your last one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opinionated with a few exceptions\n",
    "While some parameters can be modified to control how variable type inference and preprocessing are performed, the API is designed to prevent parameter proliferation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validate all the things\n",
    "Everything in Poniard is run with cross validation by default, and in fact no relevant functionality can be used without cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use baselines\n",
    "A dummy estimator is always included in model comparisons so you can gauge whether your model is better than a dumb strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast TTFM (time to first model)\n",
    "Preprocessing tries to ensure that your models run successfully without significant data munging. By default, Poniard imputes missing data and one-hot encodes or target encodes (depending on cardinality) inferred categorical variables, which in most cases is enough for scikit-learn algorithms to fit without complaints. Additionally, it scales numeric data and drops features with a single unique value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar projects\n",
    "Poniard is not a groundbreaking idea, and a number of libraries follow a similar approach.\n",
    "\n",
    "**[ATOM](https://github.com/tvdboom/ATOM)** is perhaps the most similar library to Poniard, albeit with a different approach to the API.\n",
    "\n",
    "**[LazyPredict](https://github.com/shankarpandala/lazypredict)** is similar in that it runs multiple estimators and provides results for various metrics. Unlike Poniard, by default it tries most scikit-learn estimators, and is not based on cross validation.\n",
    "\n",
    "**[PyCaret](https://github.com/pycaret/pycaret)** is a whole other beast that includes model explainability, deployment, plotting, NLP, anomaly detection, etc., which leads to a list of dependencies several times larger than Poniard's, and a more complicated API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poniard",
   "language": "python",
   "name": "poniard"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
