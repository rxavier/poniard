{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9982e62d",
   "metadata": {},
   "source": [
    "# Classifier\n",
    "\n",
    "> `PoniardClassifier` inherits from `PoniardBaseEstimator`, which sets up most of the funcionality, so you should probably read the [those docs](estimators.core.ipynb) first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d952ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp estimators.classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d951d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2f43cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from typing import List, Optional, Union, Callable, Dict, Any, Sequence\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.base import ClassifierMixin, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection._split import BaseCrossValidator, BaseShuffleSplit\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from poniard.estimators.core import PoniardBaseEstimator\n",
    "from poniard.plot.plot_factory import PoniardPlotFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c963877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class PoniardClassifier(PoniardBaseEstimator):\n",
    "    \"\"\"Cross validate multiple classifiers, rank them, fine tune them and ensemble them.\n",
    "\n",
    "    PoniardClassifier takes a list/dict of scikit-learn estimators and compares their performance\n",
    "    on a list/dict of scikit-learn metrics using a predefined scikit-learn cross-validation\n",
    "    strategy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimators :\n",
    "        Estimators to evaluate.\n",
    "    metrics :\n",
    "        Metrics to compute for each estimator. This is more restrictive than sklearn's scoring\n",
    "        parameter, as it does not allow callable scorers. Single strings are cast to lists\n",
    "        automatically.\n",
    "    preprocess : bool, optional\n",
    "        If True, impute missing values, standard scale numeric data and one-hot or ordinal\n",
    "        encode categorical data.\n",
    "    scaler :\n",
    "        Numeric scaler method. Either \"standard\", \"minmax\", \"robust\" or scikit-learn Transformer.\n",
    "    high_cardinality_encoder :\n",
    "        Encoder for categorical features with high cardinality. Either \"target\" or \"ordinal\",\n",
    "        or scikit-learn Transformer.\n",
    "    numeric_imputer :\n",
    "        Imputation method. Either \"simple\", \"iterative\" or scikit-learn Transformer.\n",
    "    custom_preprocessor :\n",
    "        Preprocessor used instead of the default preprocessing pipeline. It must be able to be\n",
    "        included directly in a scikit-learn Pipeline.\n",
    "    numeric_threshold :\n",
    "        Number features with unique values above a certain threshold will be treated as numeric. If\n",
    "        float, the threshold is `numeric_threshold * samples`.\n",
    "    cardinality_threshold :\n",
    "        Non-number features with cardinality above a certain threshold will be treated as\n",
    "        ordinal encoded instead of one-hot encoded. If float, the threshold is\n",
    "        `cardinality_threshold * samples`.\n",
    "    cv :\n",
    "        Cross validation strategy. Either an integer, a scikit-learn cross validation object,\n",
    "        or an iterable.\n",
    "    verbose :\n",
    "        Verbosity level. Propagated to every scikit-learn function and estimator.\n",
    "    random_state :\n",
    "        RNG. Propagated to every scikit-learn function and estimator. The default None sets\n",
    "        random_state to 0 so that cross_validate results are comparable.\n",
    "    n_jobs :\n",
    "        Controls parallel processing. -1 uses all cores. Propagated to every scikit-learn\n",
    "        function.\n",
    "    plugins :\n",
    "        Plugin instances that run in set moments of setup, fit and plotting.\n",
    "    plot_options :\n",
    "        :class:poniard.plot.plot_factory.PoniardPlotFactory instance specifying Plotly format\n",
    "        options or None, which sets the default factory.\n",
    "    cache_transformations :\n",
    "        Whether to cache transformations and set the `memory` parameter for Pipelines. This can\n",
    "        speed up slow transformations as they are not recalculated for each estimator.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimators: Optional[\n",
    "            Union[Dict[str, ClassifierMixin], Sequence[ClassifierMixin]]\n",
    "        ] = None,\n",
    "        metrics: Optional[Union[str, Dict[str, Callable], Sequence[str]]] = None,\n",
    "        preprocess: bool = True,\n",
    "        scaler: Optional[Union[str, TransformerMixin]] = None,\n",
    "        high_cardinality_encoder: Optional[Union[str, TransformerMixin]] = None,\n",
    "        numeric_imputer: Optional[Union[str, TransformerMixin]] = None,\n",
    "        custom_preprocessor: Union[None, Pipeline, TransformerMixin] = None,\n",
    "        numeric_threshold: Union[int, float] = 0.1,\n",
    "        cardinality_threshold: Union[int, float] = 20,\n",
    "        cv: Union[int, BaseCrossValidator, BaseShuffleSplit, Sequence] = None,\n",
    "        verbose: int = 0,\n",
    "        random_state: Optional[int] = None,\n",
    "        n_jobs: Optional[int] = None,\n",
    "        plugins: Optional[Sequence[Any]] = None,\n",
    "        plot_options: Optional[PoniardPlotFactory] = None,\n",
    "        cache_transformations: bool = False,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            estimators=estimators,\n",
    "            metrics=metrics,\n",
    "            preprocess=preprocess,\n",
    "            scaler=scaler,\n",
    "            high_cardinality_encoder=high_cardinality_encoder,\n",
    "            numeric_imputer=numeric_imputer,\n",
    "            numeric_threshold=numeric_threshold,\n",
    "            custom_preprocessor=custom_preprocessor,\n",
    "            cardinality_threshold=cardinality_threshold,\n",
    "            cv=cv,\n",
    "            verbose=verbose,\n",
    "            random_state=random_state,\n",
    "            n_jobs=n_jobs,\n",
    "            plugins=plugins,\n",
    "            plot_options=plot_options,\n",
    "            cache_transformations=cache_transformations,\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def _default_estimators(self) -> List[ClassifierMixin]:\n",
    "        return [\n",
    "            LogisticRegression(\n",
    "                random_state=self.random_state, verbose=self.verbose, max_iter=5000\n",
    "            ),\n",
    "            GaussianNB(),\n",
    "            SVC(\n",
    "                kernel=\"linear\",\n",
    "                probability=True,\n",
    "                random_state=self.random_state,\n",
    "                verbose=self.verbose,\n",
    "            ),\n",
    "            KNeighborsClassifier(),\n",
    "            DecisionTreeClassifier(random_state=self.random_state),\n",
    "            RandomForestClassifier(\n",
    "                random_state=self.random_state, verbose=self.verbose, n_jobs=self.n_jobs\n",
    "            ),\n",
    "            HistGradientBoostingClassifier(\n",
    "                random_state=self.random_state, verbose=self.verbose\n",
    "            ),\n",
    "            XGBClassifier(\n",
    "                random_state=self.random_state,\n",
    "                use_label_encoder=False,\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "    def _build_metrics(self) -> Union[Dict[str, Callable], List[str], Callable]:\n",
    "        y = self.y\n",
    "        if self.target_info[\"type_\"] == \"multilabel-indicator\":\n",
    "            return [\n",
    "                \"roc_auc\",\n",
    "                \"accuracy\",\n",
    "                \"precision_macro\",\n",
    "                \"recall_macro\",\n",
    "                \"f1_macro\",\n",
    "            ]\n",
    "        elif self.target_info[\"type_\"] == \"multiclass\":\n",
    "            return [\n",
    "                \"roc_auc_ovr\",\n",
    "                \"accuracy\",\n",
    "                \"precision_macro\",\n",
    "                \"recall_macro\",\n",
    "                \"f1_macro\",\n",
    "            ]\n",
    "\n",
    "        else:\n",
    "            return [\n",
    "                \"roc_auc\",\n",
    "                \"accuracy\",\n",
    "                \"precision\",\n",
    "                \"recall\",\n",
    "                \"f1\",\n",
    "            ]\n",
    "\n",
    "    def _build_cv(self) -> BaseCrossValidator:\n",
    "        cv = self.cv or 5\n",
    "        if isinstance(cv, int):\n",
    "            if (self.y is not None) and (\n",
    "                self.target_info[\"type_\"] in (\"binary\", \"multiclass\")\n",
    "            ):\n",
    "                return StratifiedKFold(\n",
    "                    n_splits=cv, shuffle=True, random_state=self.random_state\n",
    "                )\n",
    "            else:\n",
    "                return KFold(n_splits=cv, shuffle=True, random_state=self.random_state)\n",
    "        else:\n",
    "            self._pass_instance_attrs(cv)\n",
    "            return cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90a1987",
   "metadata": {},
   "source": [
    "`PoniardClassifier` implements `PoniardClassifier._build_cv`, `PoniardClassifier._build_metrics` and `PoniardClassifier._default_estimators`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c146cb72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rxavier/poniard/blob/master/poniard/estimators/classification.py#L180){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PoniardClassifier._build_cv\n",
       "\n",
       ">      PoniardClassifier._build_cv ()"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rxavier/poniard/blob/master/poniard/estimators/classification.py#L180){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PoniardClassifier._build_cv\n",
       "\n",
       ">      PoniardClassifier._build_cv ()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(PoniardClassifier._build_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b4b41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rxavier/poniard/blob/master/poniard/estimators/classification.py#L152){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PoniardClassifier._build_metrics\n",
       "\n",
       ">      PoniardClassifier._build_metrics ()\n",
       "\n",
       "Build metrics."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rxavier/poniard/blob/master/poniard/estimators/classification.py#L152){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PoniardClassifier._build_metrics\n",
       "\n",
       ">      PoniardClassifier._build_metrics ()\n",
       "\n",
       "Build metrics."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(PoniardClassifier._build_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e6d2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rxavier/poniard/blob/master/poniard/estimators/classification.py#L126){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PoniardClassifier._default_estimators\n",
       "\n",
       ">      PoniardClassifier._default_estimators ()"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rxavier/poniard/blob/master/poniard/estimators/classification.py#L126){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PoniardClassifier._default_estimators\n",
       "\n",
       ">      PoniardClassifier._default_estimators ()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(PoniardClassifier._default_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac2ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poniard",
   "language": "python",
   "name": "poniard"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
