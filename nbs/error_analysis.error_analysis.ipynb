{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f22678e7-6b8c-4cb9-995b-c20d2a15f55d",
   "metadata": {},
   "source": [
    "# Error analysis\n",
    "\n",
    "> Understand your model's shortcomings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f667df-38d0-486c-8c09-89209170f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp error_analysis.error_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff862e3-889e-4958-80bc-13422d5fd50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98717629-3934-403b-9e2e-ac39c1729666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from typing import Optional, Sequence, Union, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from poniard.preprocessing import PoniardPreprocessor\n",
    "from poniard.utils.utils import get_kwargs, non_default_repr\n",
    "from poniard.utils.estimate import element_to_list_maybe, get_target_info\n",
    "from poniard.estimators.core import PoniardBaseEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53957f5",
   "metadata": {},
   "source": [
    "Inspecting which classes or target ranges a model struggles with the most is a vital step in the model building iterative process. `ErrorAnalyzer` aims at streamlining this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea24a4d9-de69-4d70-b2f6-d99dee4fe2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ErrorAnalyzer:\n",
    "    \"\"\"An error analyzer for predictive models.\n",
    "\n",
    "    Compare ground truth and predicted target and rank the largest deviations\n",
    "    (either by probabilities for classifiers and actual values for regressors).\n",
    "\n",
    "    This class is tightly integrated with `PoniardBaseEstimator`, but does not require it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    task :\n",
    "        The machine learning task. Either 'regression' or 'classification'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, task: str):\n",
    "        self._init_params = get_kwargs()\n",
    "        self.task = task\n",
    "        self._poniard: Optional[\"PoniardBaseEstimator\"] = None\n",
    "\n",
    "    @property\n",
    "    def _has_poniard(self):\n",
    "        return True if self._poniard is not None else False\n",
    "\n",
    "    @classmethod\n",
    "    def from_poniard(\n",
    "        cls, poniard: \"PoniardBaseEstimator\", estimator_names: Union[str, Sequence[str]]\n",
    "    ):\n",
    "        \"\"\"Use a Poniard instance to instantiate `ErrorAnalyzer`.\n",
    "\n",
    "        Automatically sets the task and gives access to the underlying data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        poniard :\n",
    "            A `PoniardClassifier` or `PoniardRegressor` instance.\n",
    "        estimator_names :\n",
    "            Array of estimators for which to compute errors.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ErrorAnalyzer :\n",
    "            An instance of the class.\n",
    "        \"\"\"\n",
    "        error_analysis = cls(task=poniard.poniard_task)\n",
    "        error_analysis._poniard = poniard\n",
    "        error_analysis.estimator_names = element_to_list_maybe(estimator_names)\n",
    "        error_analysis.type_of_target = poniard.target_info[\"type_\"]\n",
    "        return error_analysis\n",
    "\n",
    "    def _compute_predictions(self):\n",
    "        \"\"\"Compute predictions for Poniard estimators.\"\"\"\n",
    "        predictions = self._poniard.predict(estimator_names=self.estimator_names)\n",
    "        probas = None\n",
    "        if self.type_of_target in [\"binary\", \"multilabel-indicator\", \"multiclass\"]:\n",
    "            probas = self._poniard.predict_proba(estimator_names=self.estimator_names)\n",
    "        return predictions, probas\n",
    "\n",
    "    def rank_errors(\n",
    "        self,\n",
    "        y: Optional[Union[np.ndarray, pd.Series, pd.DataFrame]] = None,\n",
    "        predictions: Optional[Union[np.ndarray, pd.Series, pd.DataFrame]] = None,\n",
    "        probas: Optional[Union[np.ndarray, pd.Series, pd.DataFrame]] = None,\n",
    "        exclude_correct: bool = True,\n",
    "    ):\n",
    "        \"\"\"Compare the `y` ground truth with `predictions` and `probas` and sort by the largest deviations.\n",
    "\n",
    "        If `ErrorAnalyzer.from_poniard` was used, no data needs to be passed to this method.\n",
    "\n",
    "        In this context \"error\" refers to:\n",
    "\n",
    "        * misclassified samples in binary and multiclass problems.\n",
    "        * misclassified samples in any of the labels for multilabel problems.\n",
    "        * samples with predicted values outside the `truth - 1SD <-> truth + 1SD`\n",
    "        range for regression problems.\n",
    "        * samples with predicted values outside the `truth - 1SD <-> truth + 1SD`\n",
    "        range in any of the targets for multioutput regression problems.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y :\n",
    "            Ground truth target.\n",
    "        predictions :\n",
    "            Predicted target.\n",
    "        probas :\n",
    "            Predicted probabilities for each class in classification tasks.\n",
    "        exclude_correct :\n",
    "            Whether to exclude correctly predicted samples in the output ranking. Default True.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dict\n",
    "            Ranked errors\n",
    "        \"\"\"\n",
    "        if self._has_poniard:\n",
    "            y = self._poniard.y\n",
    "            predictions, probas = self._compute_predictions()\n",
    "            type_of_target = self.type_of_target\n",
    "            ranked_errors = {}\n",
    "            for estimator in self.estimator_names:\n",
    "                proc_probas = probas[estimator] if probas is not None else probas\n",
    "                estimator_errors = self._target_redirect(type_of_target)(\n",
    "                    y, predictions[estimator], proc_probas, exclude_correct\n",
    "                )\n",
    "                ranked_errors.update({estimator: estimator_errors})\n",
    "            return ranked_errors\n",
    "        else:\n",
    "            self.type_of_target = get_target_info(y, task=self.task)[\"type_\"]\n",
    "            return self._target_redirect(self.type_of_target)(\n",
    "                y, predictions, probas, exclude_correct\n",
    "            )\n",
    "\n",
    "    def _target_redirect(self, type_of_target: str):\n",
    "        \"\"\"A router for error ranking depending on the type of the target.\"\"\"\n",
    "        if type_of_target == \"binary\":\n",
    "            return self._rank_errors_binary\n",
    "        elif type_of_target == \"multiclass\":\n",
    "            return self._rank_errors_multiclass\n",
    "        elif type_of_target == \"multilabel-indicator\":\n",
    "            return self._rank_errors_multilabel\n",
    "        elif type_of_target == \"continuous\":\n",
    "            return self._rank_errors_continuous\n",
    "        elif type_of_target == \"continuous-multioutput\":\n",
    "            return self._rank_errors_continuous_multioutput\n",
    "        else:\n",
    "            raise NotImplementedError(\"Type of target could not be determined.\")\n",
    "\n",
    "    def _rank_errors_binary(\n",
    "        self,\n",
    "        y: Union[np.ndarray, pd.Series, pd.DataFrame],\n",
    "        predictions: Union[np.ndarray, pd.Series, pd.DataFrame],\n",
    "        probas: Union[np.ndarray, pd.Series, pd.DataFrame],\n",
    "        exclude_correct: bool = True,\n",
    "    ):\n",
    "        errors = pd.DataFrame(\n",
    "            {\n",
    "                \"y\": y,\n",
    "                \"prediction\": predictions,\n",
    "                \"proba_0\": probas[:, 0],\n",
    "                \"proba_1\": probas[:, 1],\n",
    "            }\n",
    "        )\n",
    "        if exclude_correct:\n",
    "            errors = errors.query(\"y != prediction\")\n",
    "        errors = errors.assign(error=(errors[\"y\"] - errors[\"proba_1\"]).abs())\n",
    "        ranked_errors = errors.sort_values(\"error\", ascending=False)\n",
    "        return {\"values\": ranked_errors, \"idx\": ranked_errors.index}\n",
    "\n",
    "    def _rank_errors_multiclass(\n",
    "        self,\n",
    "        y: Union[np.ndarray, pd.Series, pd.DataFrame],\n",
    "        predictions: Union[np.ndarray, pd.Series, pd.DataFrame],\n",
    "        probas: Union[np.ndarray, pd.Series, pd.DataFrame],\n",
    "        exclude_correct: bool = True,\n",
    "    ):\n",
    "        data = {\"y\": y, \"prediction\": predictions}\n",
    "        data.update({f\"proba_{i}\": probas[:, i] for i in range(len(np.unique(y)))})\n",
    "        errors = pd.DataFrame(data)\n",
    "        if exclude_correct:\n",
    "            errors = errors.query(\"y != prediction\")\n",
    "        errors = errors.assign(\n",
    "            truth_proba=[\n",
    "                errors[f\"proba_{truth}\"].iloc[idx]\n",
    "                for idx, truth in enumerate(errors[\"y\"])\n",
    "            ]\n",
    "        )\n",
    "        errors = errors.assign(error=(1 - errors[\"truth_proba\"]).abs())\n",
    "        ranked_errors = errors.sort_values(\"error\", ascending=False)\n",
    "        return {\"values\": ranked_errors, \"idx\": ranked_errors.index}\n",
    "\n",
    "    def _rank_errors_multilabel(\n",
    "        self,\n",
    "        y: Union[np.ndarray, pd.Series, pd.DataFrame],\n",
    "        predictions: Union[np.ndarray, pd.Series, pd.DataFrame],\n",
    "        probas: Union[np.ndarray, pd.Series, pd.DataFrame],\n",
    "        exclude_correct: bool = True,\n",
    "    ):\n",
    "        truth = pd.DataFrame(y, columns=[f\"y_{i}\" for i in range(y.shape[1])])\n",
    "        preds = pd.DataFrame(\n",
    "            predictions,\n",
    "            columns=[f\"prediction_{i}\" for i in range(y.shape[1])],\n",
    "        )\n",
    "        pro = pd.DataFrame(probas, columns=[f\"proba_{i}\" for i in range(y.shape[1])])\n",
    "        errors = pd.concat([truth, preds, pro], axis=1)\n",
    "        if exclude_correct:\n",
    "            errors = errors.loc[~preds.eq(y).all(axis=1)]\n",
    "        errors_per_label = (1 - errors[pro.columns]).abs()\n",
    "        last = lambda x: x[-1]\n",
    "        zero_array = np.zeros_like(errors_per_label)\n",
    "        errors_per_label = errors_per_label.mask(\n",
    "            errors[truth.columns]\n",
    "            .rename(columns=last)\n",
    "            .eq(errors[preds.columns].rename(columns=last))\n",
    "            .values,\n",
    "            zero_array,\n",
    "        )\n",
    "        errors_per_label.columns = [f\"error_{i}\" for i in range(y.shape[1])]\n",
    "        errors_per_label = errors_per_label.assign(error=errors_per_label.mean(axis=1))\n",
    "        errors = pd.concat([errors, errors_per_label], axis=1)\n",
    "        ranked_errors = errors.sort_values(\"error\", ascending=False)\n",
    "        return {\"values\": ranked_errors, \"idx\": ranked_errors.index}\n",
    "\n",
    "    def _rank_errors_continuous(\n",
    "        self,\n",
    "        y: Union[np.ndarray, pd.Series, pd.DataFrame],\n",
    "        predictions: Union[np.ndarray, pd.Series, pd.DataFrame],\n",
    "        probas=None,\n",
    "        exclude_correct: bool = True,\n",
    "    ):\n",
    "        errors = pd.DataFrame({\"y\": y, \"prediction\": predictions})\n",
    "        y_std = np.std(y)\n",
    "        if exclude_correct:\n",
    "            errors = errors.query(\"prediction < y - @y_std | prediction > y + @y_std\")\n",
    "        errors = errors.assign(error=(errors[\"y\"] - errors[\"prediction\"]).abs())\n",
    "        ranked_errors = errors.sort_values(\"error\", ascending=False)\n",
    "        return {\"values\": ranked_errors, \"idx\": ranked_errors.index}\n",
    "\n",
    "    def _rank_errors_continuous_multioutput(\n",
    "        self,\n",
    "        y: Union[np.ndarray, pd.Series, pd.DataFrame],\n",
    "        predictions: Union[np.ndarray, pd.Series, pd.DataFrame],\n",
    "        probas=None,\n",
    "        exclude_correct: bool = True,\n",
    "    ):\n",
    "        truth = pd.DataFrame(y, columns=[f\"y_{i}\" for i in range(y.shape[1])])\n",
    "        preds = pd.DataFrame(\n",
    "            predictions,\n",
    "            columns=[f\"prediction_{i}\" for i in range(y.shape[1])],\n",
    "        )\n",
    "        errors = pd.concat([truth, preds], axis=1)\n",
    "        if exclude_correct:\n",
    "            y_std = np.std(y, axis=0)\n",
    "            errors = errors.loc[\n",
    "                (\n",
    "                    (preds.values < truth.values - y_std)\n",
    "                    | (preds.values > truth.values + y_std)\n",
    "                ).any(axis=1)\n",
    "            ].loc[lambda x: ~x.index.duplicated()]\n",
    "        errors_per_target = pd.DataFrame(\n",
    "            np.abs(errors[truth.columns].values - errors[preds.columns].values)\n",
    "        ).set_index(errors.index)\n",
    "        errors_per_target.columns = [f\"error_{i}\" for i in range(y.shape[1])]\n",
    "        errors_per_target = errors_per_target.assign(\n",
    "            error=errors_per_target.mean(axis=1)\n",
    "        )\n",
    "        errors = pd.concat([errors, errors_per_target], axis=1)\n",
    "        ranked_errors = errors.sort_values(\"error\", ascending=False)\n",
    "        return {\"values\": ranked_errors, \"idx\": ranked_errors.index}\n",
    "\n",
    "    @staticmethod\n",
    "    def merge_errors(errors: Dict[str, Dict[str, Union[pd.DataFrame, pd.Series]]]):\n",
    "        \"\"\"Merge multiple error rankings. This is particularly useful when evaluating multiple estimators.\n",
    "\n",
    "        Compute how many estimators had the specific error and the average error between them.\n",
    "\n",
    "        This method works best when using `ErrorAnalyzer.from_poniard`, since `errors` can be\n",
    "        the output of `ErrorAnalyzer.rank_errors`. However, this is not required; as long as\n",
    "        `errors` is properly defined (`{str: {str: pd.DataFrame, str: pd.Series}}`)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        errors :\n",
    "            Dictionary of errors and error indexes.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dict\n",
    "            Merged errors\n",
    "        \"\"\"\n",
    "        concatenated = pd.concat(\n",
    "            [\n",
    "                error_dict[\"values\"].assign(estimator=estimator)\n",
    "                for estimator, error_dict in errors.items()\n",
    "            ]\n",
    "        ).reset_index()\n",
    "        concatenated = (\n",
    "            concatenated.groupby(\"index\")\n",
    "            .agg(\n",
    "                mean_error=pd.NamedAgg(column=\"error\", aggfunc=np.mean),\n",
    "                freq=pd.NamedAgg(column=\"error\", aggfunc=np.size),\n",
    "                estimators=pd.NamedAgg(column=\"estimator\", aggfunc=lambda x: list(x)),\n",
    "            )\n",
    "            .sort_values([\"freq\", \"mean_error\"], ascending=False)\n",
    "        )\n",
    "        return {\"values\": concatenated, \"idx\": concatenated.index}\n",
    "\n",
    "    def analyze_target(\n",
    "        self,\n",
    "        errors_idx: pd.Series,\n",
    "        y: Optional[Union[np.ndarray, pd.Series, pd.DataFrame]] = None,\n",
    "        reg_bins: int = 5,\n",
    "        as_ratio: bool = False,\n",
    "        wrt_target: bool = False,\n",
    "    ):\n",
    "        \"\"\"Analyze which target classes/ranges have the most errors and compare with observed\n",
    "        target distribution.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        errors_idx :\n",
    "            Index of ranked errors.\n",
    "        y :\n",
    "            Ground truth. Not needed if using `ErrorAnalyzer.from_poniard`.\n",
    "        reg_bins :\n",
    "            Number of bins in which to place ground truth targets for regression tasks.\n",
    "        as_ratio :\n",
    "            Whether to show error ratios instead of error counts per class/bin. Default False.\n",
    "        wrt_target :\n",
    "            Whether to compute counts of errors or error ratios with respect\n",
    "            to the ground truth. Default False.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            Counts per error.\n",
    "        \"\"\"\n",
    "        type_of_target = self.type_of_target\n",
    "        if self._has_poniard:\n",
    "            y = self._poniard.y\n",
    "        y = pd.DataFrame(y)\n",
    "        y_errors = y.iloc[errors_idx]\n",
    "\n",
    "        if type_of_target in [\"binary\", \"multiclass\", \"multilabel-indicator\"]:\n",
    "            target_names = y.columns.tolist()\n",
    "        elif type_of_target == \"continuous\":\n",
    "            bins = pd.qcut(y.squeeze(), q=reg_bins)\n",
    "            y = y.assign(bins=bins)\n",
    "            y_errors = y_errors.assign(bins=bins)\n",
    "            target_names = \"bins\"\n",
    "        elif type_of_target == \"continuous-multioutput\":\n",
    "            bins = {\n",
    "                f\"bin_{target}\": pd.qcut(y[target], q=reg_bins)\n",
    "                for target in range(y.shape[1])\n",
    "            }\n",
    "            y = y.assign(**bins)\n",
    "            y_errors = y_errors.assign(**bins)\n",
    "            target_names = list(bins.keys())\n",
    "        else:\n",
    "            raise NotImplementedError(\"Type of target could not be determined.\")\n",
    "        errors_dist = y_errors.groupby(target_names).size()\n",
    "        target_dist = y.groupby(target_names).size()\n",
    "        if as_ratio:\n",
    "            errors_dist = errors_dist / errors_dist.sum()\n",
    "            target_dist = target_dist / target_dist.sum()\n",
    "        if wrt_target:\n",
    "            output = (errors_dist / target_dist).fillna(0).sort_values(ascending=False)\n",
    "        else:\n",
    "            output = pd.DataFrame(errors_dist).join(\n",
    "                pd.DataFrame(target_dist),\n",
    "                how=\"right\",\n",
    "                lsuffix=\"_errors\",\n",
    "                rsuffix=\"_target\",\n",
    "            )\n",
    "            output = output.fillna(0).sort_values(by=output.columns[0], ascending=False)\n",
    "        return output\n",
    "\n",
    "    def analyze_features(\n",
    "        self,\n",
    "        errors_idx: pd.Series,\n",
    "        X: Optional[Union[np.ndarray, pd.Series, pd.DataFrame]] = None,\n",
    "        features: Optional[Sequence[Union[str, int]]] = None,\n",
    "        estimator_name: Optional[Union[str, BaseEstimator]] = None,\n",
    "        n_features: Optional[Union[int, float]] = None,\n",
    "    ):\n",
    "        \"\"\"Cross tabulate features with prediction errors.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        errors_idx :\n",
    "            Index of ranked errors.\n",
    "        X :\n",
    "            Features array. Not needed if using `ErrorAnalyzer.from_poniard`.\n",
    "        features :\n",
    "            Array of features to analyze. If `None`, all features will be analyzed.\n",
    "        estimator_name :\n",
    "            Only valid if using `ErrorAnalyzer.from_poniard`. Allows using an estimator to\n",
    "            compute permutation importances and analyzing only the top `n_features`.\n",
    "        n_features :\n",
    "            How many features to analyze based on permutation importances.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, pd.DataFrame]\n",
    "            Per feature summary.\n",
    "        \"\"\"\n",
    "        if self._has_poniard:\n",
    "            X = self._poniard.X\n",
    "            feature_types = self._poniard.feature_types.items()\n",
    "        else:\n",
    "            feature_types = (\n",
    "                PoniardPreprocessor(task=\"placeholder\")\n",
    "                .build(X, np.zeros((X.shape[0],)))\n",
    "                .feature_types\n",
    "            )\n",
    "        inverted_feature_types = {}\n",
    "        for k, v in feature_types:\n",
    "            for i in v:\n",
    "                inverted_feature_types[i] = k\n",
    "        X = pd.DataFrame(X).assign(error=lambda x: x.index.isin(errors_idx).astype(int))\n",
    "\n",
    "        if features:\n",
    "            most_important_idx = []\n",
    "        elif estimator_name:\n",
    "            features = []\n",
    "            model = self._poniard[estimator_name]\n",
    "            X_train, X_test, y_train, y_test = self._poniard._train_test_split_from_cv()\n",
    "            model.fit(X_train, y_train)\n",
    "            scoring = self._poniard._first_scorer(sklearn_scorer=True)\n",
    "            random_state = self._poniard.random_state\n",
    "            importances = permutation_importance(\n",
    "                model,\n",
    "                X_test,\n",
    "                y_test,\n",
    "                n_repeats=10,\n",
    "                scoring=scoring,\n",
    "                random_state=random_state,\n",
    "            )\n",
    "            sorted_importances_idx = importances.importances_mean.argsort()[::-1]\n",
    "            if n_features is None:\n",
    "                n_features = 0.5\n",
    "            if isinstance(n_features, float):\n",
    "                assert 0 <= n_features <= 1\n",
    "                n_features = round(n_features * X.shape[1])\n",
    "            most_important_idx = sorted_importances_idx[:n_features].tolist()\n",
    "        else:\n",
    "            features = X.columns\n",
    "            most_important_idx = []\n",
    "        summary = {}\n",
    "        for i, feature in enumerate(X.columns):\n",
    "            if (i in most_important_idx or feature in features) and feature != \"error\":\n",
    "                current_feature_type = inverted_feature_types[feature]\n",
    "                if current_feature_type == \"numeric\":\n",
    "                    feature_summary = X.groupby(\"error\")[feature].describe()\n",
    "                else:\n",
    "                    feature_summary = (\n",
    "                        X.groupby(\"error\")[feature]\n",
    "                        .value_counts(normalize=True, dropna=False)\n",
    "                        .rename(\"data\")\n",
    "                        .reset_index(feature)\n",
    "                        .pivot(columns=feature, values=\"data\")\n",
    "                    )\n",
    "                summary[feature] = feature_summary\n",
    "        return summary\n",
    "\n",
    "    def __repr__(self):\n",
    "        return non_default_repr(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb26a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rxavier/poniard/blob/master/poniard/error_analysis/error_analysis.py#L44){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ErrorAnalyzer.from_poniard\n",
       "\n",
       ">      ErrorAnalyzer.from_poniard\n",
       ">                                  (poniard:poniard.estimators.core.PoniardBaseE\n",
       ">                                  stimator,\n",
       ">                                  estimator_names:Union[str,Sequence[str]])\n",
       "\n",
       "Use a Poniard instance to instantiate `ErrorAnalyzer`.\n",
       "\n",
       "Automatically sets the task and gives access to the underlying data.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| poniard | PoniardBaseEstimator | A `PoniardClassifier` or `PoniardRegressor` instance. |\n",
       "| estimator_names | typing.Union[str, typing.Sequence[str]] | Array of estimators for which to compute errors. |\n",
       "| **Returns** |  | **An instance of the class.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rxavier/poniard/blob/master/poniard/error_analysis/error_analysis.py#L44){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ErrorAnalyzer.from_poniard\n",
       "\n",
       ">      ErrorAnalyzer.from_poniard\n",
       ">                                  (poniard:poniard.estimators.core.PoniardBaseE\n",
       ">                                  stimator,\n",
       ">                                  estimator_names:Union[str,Sequence[str]])\n",
       "\n",
       "Use a Poniard instance to instantiate `ErrorAnalyzer`.\n",
       "\n",
       "Automatically sets the task and gives access to the underlying data.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| poniard | PoniardBaseEstimator | A `PoniardClassifier` or `PoniardRegressor` instance. |\n",
       "| estimator_names | typing.Union[str, typing.Sequence[str]] | Array of estimators for which to compute errors. |\n",
       "| **Returns** |  | **An instance of the class.** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ErrorAnalyzer.from_poniard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985d7e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rxavier/poniard/blob/master/poniard/error_analysis/error_analysis.py#L77){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ErrorAnalyzer.rank_errors\n",
       "\n",
       ">      ErrorAnalyzer.rank_errors (y:Union[numpy.ndarray,pandas.core.series.Serie\n",
       ">                                 s,pandas.core.frame.DataFrame,NoneType]=None, \n",
       ">                                 predictions:Union[numpy.ndarray,pandas.core.se\n",
       ">                                 ries.Series,pandas.core.frame.DataFrame,NoneTy\n",
       ">                                 pe]=None, probas:Union[numpy.ndarray,pandas.co\n",
       ">                                 re.series.Series,pandas.core.frame.DataFrame,N\n",
       ">                                 oneType]=None, exclude_correct:bool=True)\n",
       "\n",
       "Compare the `y` ground truth with `predictions` and `probas` and sort by the largest deviations.\n",
       "\n",
       "If `ErrorAnalyzer.from_poniard` was used, no data needs to be passed to this method.\n",
       "\n",
       "In this context \"error\" refers to:\n",
       "\n",
       "* misclassified samples in binary and multiclass problems.\n",
       "* misclassified samples in any of the labels for multilabel problems.\n",
       "* samples with predicted values outside the `truth - 1SD <-> truth + 1SD`\n",
       "range for regression problems.\n",
       "* samples with predicted values outside the `truth - 1SD <-> truth + 1SD`\n",
       "range in any of the targets for multioutput regression problems.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| y | typing.Union[numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, NoneType] | None | Ground truth target. |\n",
       "| predictions | typing.Union[numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, NoneType] | None | Predicted target. |\n",
       "| probas | typing.Union[numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, NoneType] | None | Predicted probabilities for each class in classification tasks. |\n",
       "| exclude_correct | bool | True | Whether to exclude correctly predicted samples in the output ranking. Default True. |\n",
       "| **Returns** | **Dict** |  | **Ranked errors** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rxavier/poniard/blob/master/poniard/error_analysis/error_analysis.py#L77){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ErrorAnalyzer.rank_errors\n",
       "\n",
       ">      ErrorAnalyzer.rank_errors (y:Union[numpy.ndarray,pandas.core.series.Serie\n",
       ">                                 s,pandas.core.frame.DataFrame,NoneType]=None, \n",
       ">                                 predictions:Union[numpy.ndarray,pandas.core.se\n",
       ">                                 ries.Series,pandas.core.frame.DataFrame,NoneTy\n",
       ">                                 pe]=None, probas:Union[numpy.ndarray,pandas.co\n",
       ">                                 re.series.Series,pandas.core.frame.DataFrame,N\n",
       ">                                 oneType]=None, exclude_correct:bool=True)\n",
       "\n",
       "Compare the `y` ground truth with `predictions` and `probas` and sort by the largest deviations.\n",
       "\n",
       "If `ErrorAnalyzer.from_poniard` was used, no data needs to be passed to this method.\n",
       "\n",
       "In this context \"error\" refers to:\n",
       "\n",
       "* misclassified samples in binary and multiclass problems.\n",
       "* misclassified samples in any of the labels for multilabel problems.\n",
       "* samples with predicted values outside the `truth - 1SD <-> truth + 1SD`\n",
       "range for regression problems.\n",
       "* samples with predicted values outside the `truth - 1SD <-> truth + 1SD`\n",
       "range in any of the targets for multioutput regression problems.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| y | typing.Union[numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, NoneType] | None | Ground truth target. |\n",
       "| predictions | typing.Union[numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, NoneType] | None | Predicted target. |\n",
       "| probas | typing.Union[numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, NoneType] | None | Predicted probabilities for each class in classification tasks. |\n",
       "| exclude_correct | bool | True | Whether to exclude correctly predicted samples in the output ranking. Default True. |\n",
       "| **Returns** | **Dict** |  | **Ranked errors** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ErrorAnalyzer.rank_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b0646d",
   "metadata": {},
   "source": [
    "`ErrorAnalyzer.rank_errors` works for simple classification..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f61cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from poniard import PoniardClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e7ed4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>prediction</th>\n",
       "      <th>proba_0</th>\n",
       "      <th>proba_1</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.997606</td>\n",
       "      <td>0.997606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.060207</td>\n",
       "      <td>0.939793</td>\n",
       "      <td>0.939793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.062019</td>\n",
       "      <td>0.937981</td>\n",
       "      <td>0.937981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.115223</td>\n",
       "      <td>0.884777</td>\n",
       "      <td>0.884777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.215570</td>\n",
       "      <td>0.784430</td>\n",
       "      <td>0.784430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.278617</td>\n",
       "      <td>0.721383</td>\n",
       "      <td>0.721383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.694271</td>\n",
       "      <td>0.305729</td>\n",
       "      <td>0.694271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.344298</td>\n",
       "      <td>0.655702</td>\n",
       "      <td>0.655702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.397514</td>\n",
       "      <td>0.602486</td>\n",
       "      <td>0.602486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585451</td>\n",
       "      <td>0.414549</td>\n",
       "      <td>0.585451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524384</td>\n",
       "      <td>0.475616</td>\n",
       "      <td>0.524384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.490481</td>\n",
       "      <td>0.509519</td>\n",
       "      <td>0.509519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y  prediction   proba_0   proba_1     error\n",
       "297  0           1  0.002394  0.997606  0.997606\n",
       "73   0           1  0.060207  0.939793  0.939793\n",
       "40   0           1  0.062019  0.937981  0.937981\n",
       "135  0           1  0.115223  0.884777  0.884777\n",
       "190  0           1  0.215570  0.784430  0.784430\n",
       "263  0           1  0.278617  0.721383  0.721383\n",
       "68   1           0  0.694271  0.305729  0.694271\n",
       "213  0           1  0.344298  0.655702  0.655702\n",
       "146  0           1  0.397514  0.602486  0.602486\n",
       "541  1           0  0.585451  0.414549  0.585451\n",
       "363  1           0  0.524384  0.475616  0.524384\n",
       "255  0           1  0.490481  0.509519  0.509519"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "pnd = (\n",
    "    PoniardClassifier(estimators=[KNeighborsClassifier(), LogisticRegression()])\n",
    "    .setup(x, y, show_info=False)\n",
    "    .fit()\n",
    ")\n",
    "error_analysis = ErrorAnalyzer.from_poniard(\n",
    "    pnd, [\"KNeighborsClassifier\", \"LogisticRegression\"]\n",
    ")\n",
    "ranked_errors = error_analysis.rank_errors()\n",
    "ranked_errors[\"LogisticRegression\"][\"values\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84682be9",
   "metadata": {},
   "source": [
    "As well as more complicated setups, such as multioutput regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863c54da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "from poniard import PoniardRegressor\n",
    "from poniard.preprocessing import PoniardPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e85444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafxavier/Documents/Repos/personal/poniard/poniard/preprocessing/core.py:145: UserWarning: TargetEncoder is not supported for multilabel or multioutput targets. Switching to OrdinalEncoder.\n",
      "  ) = self._setup_transformers()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_0</th>\n",
       "      <th>y_1</th>\n",
       "      <th>prediction_0</th>\n",
       "      <th>prediction_1</th>\n",
       "      <th>error_0</th>\n",
       "      <th>error_1</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>-285.183722</td>\n",
       "      <td>-361.210314</td>\n",
       "      <td>-83.567331</td>\n",
       "      <td>-174.502727</td>\n",
       "      <td>201.616391</td>\n",
       "      <td>186.707587</td>\n",
       "      <td>194.161989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>-206.914531</td>\n",
       "      <td>-316.893779</td>\n",
       "      <td>-68.562490</td>\n",
       "      <td>-119.157106</td>\n",
       "      <td>138.352042</td>\n",
       "      <td>197.736673</td>\n",
       "      <td>168.044357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>-193.559624</td>\n",
       "      <td>-270.201613</td>\n",
       "      <td>-47.648875</td>\n",
       "      <td>-83.285570</td>\n",
       "      <td>145.910749</td>\n",
       "      <td>186.916043</td>\n",
       "      <td>166.413396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>166.559570</td>\n",
       "      <td>307.797957</td>\n",
       "      <td>44.254690</td>\n",
       "      <td>110.607538</td>\n",
       "      <td>122.304880</td>\n",
       "      <td>197.190419</td>\n",
       "      <td>159.747649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>199.955678</td>\n",
       "      <td>175.857068</td>\n",
       "      <td>0.293321</td>\n",
       "      <td>62.923251</td>\n",
       "      <td>199.662358</td>\n",
       "      <td>112.933817</td>\n",
       "      <td>156.298087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>138.150171</td>\n",
       "      <td>34.382971</td>\n",
       "      <td>60.332156</td>\n",
       "      <td>27.100214</td>\n",
       "      <td>77.818015</td>\n",
       "      <td>7.282756</td>\n",
       "      <td>42.550386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>-94.526886</td>\n",
       "      <td>-32.665129</td>\n",
       "      <td>-15.892835</td>\n",
       "      <td>-27.263218</td>\n",
       "      <td>78.634051</td>\n",
       "      <td>5.401912</td>\n",
       "      <td>42.017982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-6.393304</td>\n",
       "      <td>65.144850</td>\n",
       "      <td>73.175490</td>\n",
       "      <td>61.991206</td>\n",
       "      <td>79.568794</td>\n",
       "      <td>3.153644</td>\n",
       "      <td>41.361219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>1.808688</td>\n",
       "      <td>-64.975064</td>\n",
       "      <td>-76.728970</td>\n",
       "      <td>-61.481938</td>\n",
       "      <td>78.537658</td>\n",
       "      <td>3.493126</td>\n",
       "      <td>41.015392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>60.170481</td>\n",
       "      <td>-36.460608</td>\n",
       "      <td>-17.018031</td>\n",
       "      <td>-35.620963</td>\n",
       "      <td>77.188512</td>\n",
       "      <td>0.839645</td>\n",
       "      <td>39.014078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y_0         y_1  prediction_0  prediction_1     error_0  \\\n",
       "679 -285.183722 -361.210314    -83.567331   -174.502727  201.616391   \n",
       "580 -206.914531 -316.893779    -68.562490   -119.157106  138.352042   \n",
       "466 -193.559624 -270.201613    -47.648875    -83.285570  145.910749   \n",
       "543  166.559570  307.797957     44.254690    110.607538  122.304880   \n",
       "110  199.955678  175.857068      0.293321     62.923251  199.662358   \n",
       "..          ...         ...           ...           ...         ...   \n",
       "563  138.150171   34.382971     60.332156     27.100214   77.818015   \n",
       "911  -94.526886  -32.665129    -15.892835    -27.263218   78.634051   \n",
       "441   -6.393304   65.144850     73.175490     61.991206   79.568794   \n",
       "582    1.808688  -64.975064    -76.728970    -61.481938   78.537658   \n",
       "794   60.170481  -36.460608    -17.018031    -35.620963   77.188512   \n",
       "\n",
       "        error_1       error  \n",
       "679  186.707587  194.161989  \n",
       "580  197.736673  168.044357  \n",
       "466  186.916043  166.413396  \n",
       "543  197.190419  159.747649  \n",
       "110  112.933817  156.298087  \n",
       "..          ...         ...  \n",
       "563    7.282756   42.550386  \n",
       "911    5.401912   42.017982  \n",
       "441    3.153644   41.361219  \n",
       "582    3.493126   41.015392  \n",
       "794    0.839645   39.014078  \n",
       "\n",
       "[302 rows x 7 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = make_regression(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    n_targets=2,\n",
    "    n_informative=3,\n",
    "    noise=50,\n",
    "    random_state=0,\n",
    ")\n",
    "x += np.random.normal()\n",
    "prep = PoniardPreprocessor(numeric_threshold=10)\n",
    "pnd = (\n",
    "    PoniardRegressor(\n",
    "        estimators={\n",
    "            \"lr\": MultiOutputRegressor(LinearRegression()),\n",
    "            \"knn\": MultiOutputRegressor(KNeighborsRegressor()),\n",
    "        },\n",
    "        custom_preprocessor=prep,\n",
    "    )\n",
    "    .setup(x, y, show_info=False)\n",
    "    .fit()\n",
    ")\n",
    "error_analysis = ErrorAnalyzer.from_poniard(pnd, [\"lr\", \"knn\"])\n",
    "ranked_errors = error_analysis.rank_errors()\n",
    "ranked_errors[\"knn\"][\"values\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d886e329",
   "metadata": {},
   "source": [
    "It can also be used without Poniard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb489138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from poniard import PoniardRegressor\n",
    "from poniard.preprocessing import PoniardPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8465cebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>-464.670855</td>\n",
       "      <td>-0.350707</td>\n",
       "      <td>464.320148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>404.418950</td>\n",
       "      <td>-0.350707</td>\n",
       "      <td>404.769658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>315.697748</td>\n",
       "      <td>-0.350707</td>\n",
       "      <td>316.048455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>296.745975</td>\n",
       "      <td>-0.350707</td>\n",
       "      <td>297.096683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>251.852262</td>\n",
       "      <td>-0.350707</td>\n",
       "      <td>252.202970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>244.731893</td>\n",
       "      <td>-0.350707</td>\n",
       "      <td>245.082601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>-239.847177</td>\n",
       "      <td>-0.350707</td>\n",
       "      <td>239.496470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-210.915148</td>\n",
       "      <td>-0.350707</td>\n",
       "      <td>210.564440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>-191.913223</td>\n",
       "      <td>-0.350707</td>\n",
       "      <td>191.562515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>-189.187016</td>\n",
       "      <td>-0.350707</td>\n",
       "      <td>188.836309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>-177.730938</td>\n",
       "      <td>-0.350707</td>\n",
       "      <td>177.380231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>-166.952328</td>\n",
       "      <td>-0.350707</td>\n",
       "      <td>166.601621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>159.823319</td>\n",
       "      <td>-0.350707</td>\n",
       "      <td>160.174026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>158.426090</td>\n",
       "      <td>-0.350707</td>\n",
       "      <td>158.776798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>-153.961482</td>\n",
       "      <td>-0.350707</td>\n",
       "      <td>153.610775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>141.202852</td>\n",
       "      <td>-0.350707</td>\n",
       "      <td>141.553559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               y  prediction       error\n",
       "152  -464.670855   -0.350707  464.320148\n",
       "975   404.418950   -0.350707  404.769658\n",
       "1766  315.697748   -0.350707  316.048455\n",
       "1633  296.745975   -0.350707  297.096683\n",
       "842   251.852262   -0.350707  252.202970\n",
       "1207  244.731893   -0.350707  245.082601\n",
       "1269 -239.847177   -0.350707  239.496470\n",
       "55   -210.915148   -0.350707  210.564440\n",
       "1236 -191.913223   -0.350707  191.562515\n",
       "1076 -189.187016   -0.350707  188.836309\n",
       "364  -177.730938   -0.350707  177.380231\n",
       "1012 -166.952328   -0.350707  166.601621\n",
       "215   159.823319   -0.350707  160.174026\n",
       "1463  158.426090   -0.350707  158.776798\n",
       "213  -153.961482   -0.350707  153.610775\n",
       "292   141.202852   -0.350707  141.553559"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = make_regression(\n",
    "    n_samples=2000,\n",
    "    n_features=10,\n",
    "    n_targets=1,\n",
    "    n_informative=3,\n",
    "    noise=50,\n",
    "    random_state=0,\n",
    ")\n",
    "x += np.random.normal()\n",
    "y_pred = y.copy()\n",
    "y_pred[np.random.randint(0, y.shape[0], 50)] = np.random.normal()\n",
    "\n",
    "error_analysis = ErrorAnalyzer(task=\"regression\")\n",
    "ranked_errors = error_analysis.rank_errors(y, y_pred)\n",
    "ranked_errors[\"values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0c031a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rxavier/poniard/blob/master/poniard/error_analysis/error_analysis.py#L269){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ErrorAnalyzer.merge_errors\n",
       "\n",
       ">      ErrorAnalyzer.merge_errors (errors:Dict[str,Dict[str,Union[pandas.core.fr\n",
       ">                                  ame.DataFrame,pandas.core.series.Series]]])\n",
       "\n",
       "Merge multiple error rankings. This is particularly useful when evaluating multiple estimators.\n",
       "\n",
       "Compute how many estimators had the specific error and the average error between them.\n",
       "\n",
       "This method works best when using `ErrorAnalyzer.from_poniard`, since `errors` can be \n",
       "the output of `ErrorAnalyzer.rank_errors`. However, this is not required; as long as \n",
       "`errors` is properly defined (`{str: {str: pd.DataFrame, str: pd.Series}}`)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| errors | typing.Dict[str, typing.Dict[str, typing.Union[pandas.core.frame.DataFrame, pandas.core.series.Series]]] | Dictionary of errors and error indexes. |\n",
       "| **Returns** | **Dict** | **Merged errors** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rxavier/poniard/blob/master/poniard/error_analysis/error_analysis.py#L269){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ErrorAnalyzer.merge_errors\n",
       "\n",
       ">      ErrorAnalyzer.merge_errors (errors:Dict[str,Dict[str,Union[pandas.core.fr\n",
       ">                                  ame.DataFrame,pandas.core.series.Series]]])\n",
       "\n",
       "Merge multiple error rankings. This is particularly useful when evaluating multiple estimators.\n",
       "\n",
       "Compute how many estimators had the specific error and the average error between them.\n",
       "\n",
       "This method works best when using `ErrorAnalyzer.from_poniard`, since `errors` can be \n",
       "the output of `ErrorAnalyzer.rank_errors`. However, this is not required; as long as \n",
       "`errors` is properly defined (`{str: {str: pd.DataFrame, str: pd.Series}}`)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| errors | typing.Dict[str, typing.Dict[str, typing.Union[pandas.core.frame.DataFrame, pandas.core.series.Series]]] | Dictionary of errors and error indexes. |\n",
       "| **Returns** | **Dict** | **Merged errors** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ErrorAnalyzer.merge_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244454b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "\n",
    "from poniard import PoniardClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4466c0b-1ab4-40b1-be67-dd156792ef18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_error</th>\n",
       "      <th>freq</th>\n",
       "      <th>estimators</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.848222</td>\n",
       "      <td>3</td>\n",
       "      <td>[RandomForestClassifier, LogisticRegression, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.842455</td>\n",
       "      <td>3</td>\n",
       "      <td>[RandomForestClassifier, LogisticRegression, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.824483</td>\n",
       "      <td>3</td>\n",
       "      <td>[RandomForestClassifier, LogisticRegression, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.817890</td>\n",
       "      <td>3</td>\n",
       "      <td>[RandomForestClassifier, LogisticRegression, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.741060</td>\n",
       "      <td>3</td>\n",
       "      <td>[RandomForestClassifier, LogisticRegression, H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.909402</td>\n",
       "      <td>2</td>\n",
       "      <td>[RandomForestClassifier, HistGradientBoostingC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.793324</td>\n",
       "      <td>2</td>\n",
       "      <td>[RandomForestClassifier, HistGradientBoostingC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.763608</td>\n",
       "      <td>2</td>\n",
       "      <td>[RandomForestClassifier, HistGradientBoostingC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.610000</td>\n",
       "      <td>1</td>\n",
       "      <td>[RandomForestClassifier]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.529012</td>\n",
       "      <td>1</td>\n",
       "      <td>[LogisticRegression]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_error  freq                                         estimators\n",
       "index                                                                     \n",
       "106      0.848222     3  [RandomForestClassifier, LogisticRegression, H...\n",
       "70       0.842455     3  [RandomForestClassifier, LogisticRegression, H...\n",
       "77       0.824483     3  [RandomForestClassifier, LogisticRegression, H...\n",
       "119      0.817890     3  [RandomForestClassifier, LogisticRegression, H...\n",
       "133      0.741060     3  [RandomForestClassifier, LogisticRegression, H...\n",
       "83       0.909402     2  [RandomForestClassifier, HistGradientBoostingC...\n",
       "72       0.793324     2  [RandomForestClassifier, HistGradientBoostingC...\n",
       "129      0.763608     2  [RandomForestClassifier, HistGradientBoostingC...\n",
       "138      0.610000     1                           [RandomForestClassifier]\n",
       "134      0.529012     1                               [LogisticRegression]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = load_iris(return_X_y=True, as_frame=True)\n",
    "pnd = (\n",
    "    PoniardClassifier(\n",
    "        estimators=[\n",
    "            LogisticRegression(),\n",
    "            RandomForestClassifier(),\n",
    "            HistGradientBoostingClassifier(),\n",
    "        ]\n",
    "    )\n",
    "    .setup(x, y, show_info=False)\n",
    "    .fit()\n",
    ")\n",
    "error_analysis = ErrorAnalyzer.from_poniard(\n",
    "    pnd,\n",
    "    [\"RandomForestClassifier\", \"LogisticRegression\", \"HistGradientBoostingClassifier\"],\n",
    ")\n",
    "ranked_errors = error_analysis.rank_errors()\n",
    "merged_errors = error_analysis.merge_errors(ranked_errors)\n",
    "merged_errors[\"values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547a2ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rxavier/poniard/blob/master/poniard/error_analysis/error_analysis.py#L305){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ErrorAnalyzer.analyze_target\n",
       "\n",
       ">      ErrorAnalyzer.analyze_target (errors_idx:pandas.core.series.Series, y:Uni\n",
       ">                                    on[numpy.ndarray,pandas.core.series.Series,\n",
       ">                                    pandas.core.frame.DataFrame,NoneType]=None,\n",
       ">                                    reg_bins:int=5, as_ratio:bool=False,\n",
       ">                                    wrt_target:bool=False)\n",
       "\n",
       "Analyze which target classes/ranges have the most errors and compare with observed\n",
       "target distribution.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| errors_idx | Series |  | Index of ranked errors. |\n",
       "| y | typing.Union[numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, NoneType] | None | Ground truth. Not needed if using `ErrorAnalyzer.from_poniard`. |\n",
       "| reg_bins | int | 5 | Number of bins in which to place ground truth targets for regression tasks. |\n",
       "| as_ratio | bool | False | Whether to show error ratios instead of error counts per class/bin. Default False. |\n",
       "| wrt_target | bool | False | Whether to compute counts of errors or error ratios with respect<br>to the ground truth. Default False. |\n",
       "| **Returns** | **pd.DataFrame** |  | **Counts per error.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rxavier/poniard/blob/master/poniard/error_analysis/error_analysis.py#L305){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ErrorAnalyzer.analyze_target\n",
       "\n",
       ">      ErrorAnalyzer.analyze_target (errors_idx:pandas.core.series.Series, y:Uni\n",
       ">                                    on[numpy.ndarray,pandas.core.series.Series,\n",
       ">                                    pandas.core.frame.DataFrame,NoneType]=None,\n",
       ">                                    reg_bins:int=5, as_ratio:bool=False,\n",
       ">                                    wrt_target:bool=False)\n",
       "\n",
       "Analyze which target classes/ranges have the most errors and compare with observed\n",
       "target distribution.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| errors_idx | Series |  | Index of ranked errors. |\n",
       "| y | typing.Union[numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, NoneType] | None | Ground truth. Not needed if using `ErrorAnalyzer.from_poniard`. |\n",
       "| reg_bins | int | 5 | Number of bins in which to place ground truth targets for regression tasks. |\n",
       "| as_ratio | bool | False | Whether to show error ratios instead of error counts per class/bin. Default False. |\n",
       "| wrt_target | bool | False | Whether to compute counts of errors or error ratios with respect<br>to the ground truth. Default False. |\n",
       "| **Returns** | **pd.DataFrame** |  | **Counts per error.** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ErrorAnalyzer.analyze_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc03e6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from poniard import PoniardRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74433abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_errors</th>\n",
       "      <th>0_target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bins</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(232.0, 346.0]</th>\n",
       "      <td>33</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(24.999, 77.0]</th>\n",
       "      <td>18</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(77.0, 115.0]</th>\n",
       "      <td>9</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(168.0, 232.0]</th>\n",
       "      <td>9</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(115.0, 168.0]</th>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0_errors  0_target\n",
       "bins                              \n",
       "(232.0, 346.0]        33        88\n",
       "(24.999, 77.0]        18        91\n",
       "(77.0, 115.0]          9        87\n",
       "(168.0, 232.0]         9        87\n",
       "(115.0, 168.0]         5        89"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = load_diabetes(return_X_y=True, as_frame=True)\n",
    "pnd = PoniardRegressor(estimators=LinearRegression()).setup(x, y, show_info=False).fit()\n",
    "error_analysis = ErrorAnalyzer.from_poniard(pnd, [\"LinearRegression\"])\n",
    "ranked_errors = error_analysis.rank_errors()\n",
    "\n",
    "error_analysis.analyze_target(ranked_errors[\"LinearRegression\"][\"idx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805caa8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bins\n",
       "(232.0, 346.0]    0.375000\n",
       "(24.999, 77.0]    0.197802\n",
       "(77.0, 115.0]     0.103448\n",
       "(168.0, 232.0]    0.103448\n",
       "(115.0, 168.0]    0.056180\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_analysis.analyze_target(ranked_errors[\"LinearRegression\"][\"idx\"], wrt_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3aa3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rxavier/poniard/blob/master/poniard/error_analysis/error_analysis.py#L375){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ErrorAnalyzer.analyze_features\n",
       "\n",
       ">      ErrorAnalyzer.analyze_features (errors_idx:pandas.core.series.Series, X:U\n",
       ">                                      nion[numpy.ndarray,pandas.core.series.Ser\n",
       ">                                      ies,pandas.core.frame.DataFrame,NoneType]\n",
       ">                                      =None, features:Union[Sequence[Union[str,\n",
       ">                                      int]],NoneType]=None, estimator_name:Unio\n",
       ">                                      n[str,sklearn.base.BaseEstimator,NoneType\n",
       ">                                      ]=None, n_features:Union[int,float,NoneTy\n",
       ">                                      pe]=None)\n",
       "\n",
       "Cross tabulate features with prediction errors.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| errors_idx | Series |  | Index of ranked errors. |\n",
       "| X | typing.Union[numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, NoneType] | None | Features array. Not needed if using `ErrorAnalyzer.from_poniard`. |\n",
       "| features | typing.Union[typing.Sequence[typing.Union[str, int]], NoneType] | None | Array of features to analyze. If `None`, all features will be analyzed. |\n",
       "| estimator_name | typing.Union[str, sklearn.base.BaseEstimator, NoneType] | None | Only valid if using `ErrorAnalyzer.from_poniard`. Allows using an estimator to<br>compute permutation importances and analyzing only the top `n_features`. |\n",
       "| n_features | typing.Union[int, float, NoneType] | None | How many features to analyze based on permutation importances. |\n",
       "| **Returns** | **Dict[str, pd.DataFrame]** |  | **Per feature summary.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rxavier/poniard/blob/master/poniard/error_analysis/error_analysis.py#L375){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ErrorAnalyzer.analyze_features\n",
       "\n",
       ">      ErrorAnalyzer.analyze_features (errors_idx:pandas.core.series.Series, X:U\n",
       ">                                      nion[numpy.ndarray,pandas.core.series.Ser\n",
       ">                                      ies,pandas.core.frame.DataFrame,NoneType]\n",
       ">                                      =None, features:Union[Sequence[Union[str,\n",
       ">                                      int]],NoneType]=None, estimator_name:Unio\n",
       ">                                      n[str,sklearn.base.BaseEstimator,NoneType\n",
       ">                                      ]=None, n_features:Union[int,float,NoneTy\n",
       ">                                      pe]=None)\n",
       "\n",
       "Cross tabulate features with prediction errors.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| errors_idx | Series |  | Index of ranked errors. |\n",
       "| X | typing.Union[numpy.ndarray, pandas.core.series.Series, pandas.core.frame.DataFrame, NoneType] | None | Features array. Not needed if using `ErrorAnalyzer.from_poniard`. |\n",
       "| features | typing.Union[typing.Sequence[typing.Union[str, int]], NoneType] | None | Array of features to analyze. If `None`, all features will be analyzed. |\n",
       "| estimator_name | typing.Union[str, sklearn.base.BaseEstimator, NoneType] | None | Only valid if using `ErrorAnalyzer.from_poniard`. Allows using an estimator to<br>compute permutation importances and analyzing only the top `n_features`. |\n",
       "| n_features | typing.Union[int, float, NoneType] | None | How many features to analyze based on permutation importances. |\n",
       "| **Returns** | **Dict[str, pd.DataFrame]** |  | **Per feature summary.** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ErrorAnalyzer.analyze_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9502901c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>368.0</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.047873</td>\n",
       "      <td>-0.107226</td>\n",
       "      <td>-0.035483</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.110727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74.0</td>\n",
       "      <td>-0.002324</td>\n",
       "      <td>0.046585</td>\n",
       "      <td>-0.096328</td>\n",
       "      <td>-0.037299</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.026270</td>\n",
       "      <td>0.110727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count      mean       std       min       25%       50%       75%  \\\n",
       "error                                                                      \n",
       "0      368.0  0.000467  0.047873 -0.107226 -0.035483  0.005383  0.038076   \n",
       "1       74.0 -0.002324  0.046585 -0.096328 -0.037299  0.005383  0.026270   \n",
       "\n",
       "            max  \n",
       "error            \n",
       "0      0.110727  \n",
       "1      0.110727  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_analysis.analyze_features(ranked_errors[\"LinearRegression\"][\"idx\"])[\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f36075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2b2314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poniard",
   "language": "python",
   "name": "poniard"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
