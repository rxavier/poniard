{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9982e62d",
   "metadata": {},
   "source": [
    "# Categorical preprocessors\n",
    "\n",
    "> Covering use cases not handled by native scikit-learn transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d952ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp preprocessing.categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d951d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2f43cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "from __future__ import annotations\n",
    "import collections\n",
    "from typing import Union, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.utils.fixes import _object_dtype_isnan\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "from poniard.utils.estimate import get_target_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cabb131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "# | hide\n",
    "\n",
    "\n",
    "def check_input(X):\n",
    "    X_ = check_array(X, dtype=None, ensure_2d=True, force_all_finite=False)\n",
    "    # If the array contains both NaNs and strings, convert to object type\n",
    "    if X_.dtype.kind in {\"U\", \"S\"}:  # contains strings\n",
    "        if np.any(X_ == \"nan\"):  # missing value converted to string\n",
    "            return check_array(\n",
    "                np.array(X, dtype=object),\n",
    "                dtype=None,\n",
    "                ensure_2d=True,\n",
    "                force_all_finite=False,\n",
    "            )\n",
    "    return X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c963877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Encode categorical features considering the effect that it has in the\n",
    "    target variable.\n",
    "\n",
    "    Note that implementation and docstrings are largely taken from\n",
    "    [Dirty Cat](https://github.com/dirty-cat/dirty_cat/blob/master/dirty_cat/target_encoder.py).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    task :\n",
    "        The type of problem. Either \"classification\" or \"regression\".\n",
    "    handle_unknown :\n",
    "        Either \"error\" or \"ignore\". Whether to raise an error or ignore if a unknown\n",
    "        categorical feature is present during transform (default is to raise). If 'ignore',\n",
    "        unknown categories will be set to the mean of the target.\n",
    "    handle_missing :\n",
    "        Either \"error\" or \"\". Whether to raise an error or impute with blank string \"\" if missing\n",
    "        values (NaN) are present during fit (default is to impute).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, task: str, handle_unknown=\"error\", handle_missing=\"\"):\n",
    "        self.task = task\n",
    "        self.handle_unknown = handle_unknown\n",
    "        self.handle_missing = handle_missing\n",
    "\n",
    "    def _more_tags(self):\n",
    "        \"\"\"\n",
    "        Used internally by sklearn to ease the estimator checks.\n",
    "        \"\"\"\n",
    "        return {\"X_types\": [\"categorical\"]}\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X: Union[pd.DataFrame, np.ndarray, List],\n",
    "        y: Union[pd.DataFrame, np.ndarray, List],\n",
    "    ) -> TargetEncoder:\n",
    "        \"\"\"Fit the TargetEncoder to X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X :\n",
    "            The data to determine the categories of each feature.\n",
    "        y :\n",
    "            The associated target vector.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        TargetEncoder\n",
    "            Fitted TargetEncoder.\n",
    "        \"\"\"\n",
    "        self.type_of_target_ = get_target_info(y, self.task)[\"type_\"]\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.colnames_ = X.columns\n",
    "        X = check_input(X)\n",
    "        self.n_features_in_ = X.shape[1]\n",
    "        X = X.astype(str)\n",
    "        if self.handle_missing not in [\"error\", \"\"]:\n",
    "            template = \"handle_missing should be either 'error' or \" \"'', got %s\"\n",
    "            raise ValueError(template % self.handle_missing)\n",
    "        if hasattr(X, \"iloc\") and X.isna().values.any():\n",
    "            if self.handle_missing == \"error\":\n",
    "                msg = (\n",
    "                    \"Found missing values in input data; set \"\n",
    "                    \"handle_missing='' to encode with missing values\"\n",
    "                )\n",
    "                raise ValueError(msg)\n",
    "            else:\n",
    "                X = X.fillna(self.handle_missing)\n",
    "        elif not hasattr(X, \"dtype\") and isinstance(X, list):\n",
    "            X = np.asarray(X, dtype=object)\n",
    "        if hasattr(X, \"dtype\"):\n",
    "            mask = _object_dtype_isnan(X)\n",
    "            if mask.any():\n",
    "                if self.handle_missing == \"error\":\n",
    "                    msg = (\n",
    "                        \"Found missing values in input data; set \"\n",
    "                        \"handle_missing='' to encode with missing values\"\n",
    "                    )\n",
    "                    raise ValueError(msg)\n",
    "                else:\n",
    "                    X[mask] = self.handle_missing\n",
    "\n",
    "        if self.handle_unknown not in [\"error\", \"ignore\"]:\n",
    "            template = \"handle_unknown should be either 'error' or \" \"'ignore', got %s\"\n",
    "            raise ValueError(template % self.handle_unknown)\n",
    "        X_temp = check_array(X, dtype=None)\n",
    "        if not hasattr(X, \"dtype\") and np.issubdtype(X_temp.dtype, np.str_):\n",
    "            X = check_array(X, dtype=np.object)\n",
    "        else:\n",
    "            X = X_temp\n",
    "\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        self._label_encoders_ = [LabelEncoder() for _ in range(n_features)]\n",
    "\n",
    "        for j in range(n_features):\n",
    "            le = self._label_encoders_[j]\n",
    "            Xj = X[:, j]\n",
    "            le.fit(Xj)\n",
    "        self.categories_ = [le.classes_ for le in self._label_encoders_]\n",
    "        self.n_ = len(y)\n",
    "        if self.type_of_target_ == \"binary\" and np.array(y).dtype.kind not in \"biufc\":\n",
    "            y = LabelEncoder().fit_transform(y)\n",
    "        if self.type_of_target_ in [\"continuous\", \"binary\"]:\n",
    "            self.Eyx_ = [\n",
    "                {cat: np.mean(y[X[:, j] == cat]) for cat in self.categories_[j]}\n",
    "                for j in range(len(self.categories_))\n",
    "            ]\n",
    "            self.Ey_ = np.mean(y)\n",
    "            self.counter_ = {j: collections.Counter(X[:, j]) for j in range(n_features)}\n",
    "        if self.type_of_target_ == \"multiclass\":\n",
    "            self.classes_ = np.unique(y)\n",
    "\n",
    "            self.Eyx_ = {\n",
    "                c: [\n",
    "                    {\n",
    "                        cat: np.mean((y == c)[X[:, j] == cat])\n",
    "                        for cat in self.categories_[j]\n",
    "                    }\n",
    "                    for j in range(len(self.categories_))\n",
    "                ]\n",
    "                for c in self.classes_\n",
    "            }\n",
    "            self.Ey_ = {c: np.mean(y == c) for c in self.classes_}\n",
    "            self.counter_ = {j: collections.Counter(X[:, j]) for j in range(n_features)}\n",
    "        self.k_ = {j: len(self.counter_[j]) for j in self.counter_}\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: Union[pd.DataFrame, np.ndarray, List]):\n",
    "        \"\"\"Transform X using specified encoding scheme.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X :\n",
    "            The data to encode.\n",
    "        Returns\n",
    "        -------\n",
    "        X :\n",
    "            Transformed input.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, attributes=[\"n_features_in_\"])\n",
    "        X = check_input(X)\n",
    "        if X.shape[1] != self.n_features_in_:\n",
    "            raise ValueError(\n",
    "                f\"Number of features in the input data ({X.shape[1]}) does not match the number of features \"\n",
    "                f\"seen during fit ({self.n_features_in_}).\"\n",
    "            )\n",
    "        X = X.astype(str)\n",
    "        if hasattr(X, \"iloc\") and X.isna().values.any():\n",
    "            if self.handle_missing == \"error\":\n",
    "                msg = (\n",
    "                    \"Found missing values in input data; set \"\n",
    "                    \"handle_missing='' to encode with missing values\"\n",
    "                )\n",
    "                raise ValueError(msg)\n",
    "            else:\n",
    "                X = X.fillna(self.handle_missing)\n",
    "        elif not hasattr(X, \"dtype\") and isinstance(X, list):\n",
    "            X = np.asarray(X, dtype=object)\n",
    "        if hasattr(X, \"dtype\"):\n",
    "            mask = _object_dtype_isnan(X)\n",
    "            if mask.any():\n",
    "                if self.handle_missing == \"error\":\n",
    "                    msg = (\n",
    "                        \"Found missing values in input data; set \"\n",
    "                        \"handle_missing='' to encode with missing values\"\n",
    "                    )\n",
    "                    raise ValueError(msg)\n",
    "                else:\n",
    "                    X[mask] = self.handle_missing\n",
    "\n",
    "        X_temp = check_array(X, dtype=None)\n",
    "        if not hasattr(X, \"dtype\") and np.issubdtype(X_temp.dtype, np.str_):\n",
    "            X = check_array(X, dtype=np.object)\n",
    "        else:\n",
    "            X = X_temp\n",
    "\n",
    "        n_features = X.shape[1]\n",
    "        X_int = np.zeros_like(X, dtype=int)\n",
    "        X_mask = np.ones_like(X, dtype=bool)\n",
    "\n",
    "        for i in range(n_features):\n",
    "            Xi = X[:, i]\n",
    "            valid_mask = np.in1d(Xi, self.categories_[i])\n",
    "\n",
    "            if not np.all(valid_mask):\n",
    "                if self.handle_unknown == \"error\":\n",
    "                    diff = np.unique(X[~valid_mask, i])\n",
    "                    msg = (\n",
    "                        \"Found unknown categories {0} in column {1}\"\n",
    "                        \" during transform\".format(diff, i)\n",
    "                    )\n",
    "                    raise ValueError(msg)\n",
    "                else:\n",
    "                    # Set the problematic rows to an acceptable value and\n",
    "                    # continue `The rows are marked `X_mask` and will be\n",
    "                    # removed later.\n",
    "                    X_mask[:, i] = valid_mask\n",
    "                    Xi = Xi.copy()\n",
    "                    Xi[~valid_mask] = self.categories_[i][0]\n",
    "            X_int[:, i] = self._label_encoders_[i].transform(Xi)\n",
    "\n",
    "        out = []\n",
    "\n",
    "        for j, cats in enumerate(self.categories_):\n",
    "            unqX = np.unique(X[:, j])\n",
    "            encoder = {x: 0 for x in unqX}\n",
    "            if self.type_of_target_ in [\"continuous\", \"binary\"]:\n",
    "                for x in unqX:\n",
    "                    if x not in cats:\n",
    "                        Eyx = 0\n",
    "                    else:\n",
    "                        Eyx = self.Eyx_[j][x]\n",
    "                    lambda_n = self.lambda_(self.counter_[j][x], self.n_ / self.k_[j])\n",
    "                    encoder[x] = lambda_n * Eyx + (1 - lambda_n) * self.Ey_\n",
    "                x_out = np.zeros((len(X[:, j]), 1))\n",
    "                for i, x in enumerate(X[:, j]):\n",
    "                    x_out[i, 0] = encoder[x]\n",
    "                out.append(x_out.reshape(-1, 1))\n",
    "            if self.type_of_target_ == \"multiclass\":\n",
    "                x_out = np.zeros((len(X[:, j]), len(self.classes_)))\n",
    "                lambda_n = {x: 0 for x in unqX}\n",
    "                for x in unqX:\n",
    "                    lambda_n[x] = self.lambda_(\n",
    "                        self.counter_[j][x], self.n_ / self.k_[j]\n",
    "                    )\n",
    "                for k, c in enumerate(np.unique(self.classes_)):\n",
    "                    for x in unqX:\n",
    "                        if x not in cats:\n",
    "                            Eyx = 0\n",
    "                        else:\n",
    "                            Eyx = self.Eyx_[c][j][x]\n",
    "                        encoder[x] = lambda_n[x] * Eyx + (1 - lambda_n[x]) * self.Ey_[c]\n",
    "                    for i, x in enumerate(X[:, j]):\n",
    "                        x_out[i, k] = encoder[x]\n",
    "                out.append(x_out)\n",
    "        out = np.hstack(out)\n",
    "        return out\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None) -> List[str]:\n",
    "        \"\"\"Get feature names for output.\"\"\"\n",
    "        colnames_ = getattr(self, \"colnames_\", None)\n",
    "        if colnames_ is not None:\n",
    "            if self.type_of_target_ in [\"continuous\", \"binary\"]:\n",
    "                output = colnames_.tolist()\n",
    "            else:\n",
    "                output = []\n",
    "                for name in colnames_:\n",
    "                    unique = self.classes_\n",
    "                    names = [f\"{name}_{level}\" for level in unique]\n",
    "                    output.extend(names)\n",
    "            return output\n",
    "\n",
    "    def get_feature_names(self, input_features=None) -> List[str]:\n",
    "        return self.get_feature_names_out()\n",
    "\n",
    "    @staticmethod\n",
    "    def lambda_(x, n):\n",
    "        out = x / (x + n)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b4c4f3",
   "metadata": {},
   "source": [
    "In general, `TargetEncoder` takes the ratio between the mean of the target for a given category and the mean of the target. In addition, it takes an empirical Bayes approach to shrink the estimate.\n",
    "\n",
    "It is particularly useful with high cardinality categoricals, as it will not expand the feature space as much as one hot encoding, but retains more information than ordinal encoding.\n",
    "\n",
    "For more details, see [Micci-Barreca, 2001: A preprocessing scheme for high-cardinality categorical attributes in classification and prediction problems](https://dl.acm.org/doi/10.1145/507533.507538)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe5a62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rxavier/poniard/blob/master/poniard/preprocessing/categorical.py#L67){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TargetEncoder.fit\n",
       "\n",
       ">      TargetEncoder.fit\n",
       ">                         (X:Union[pandas.core.frame.DataFrame,numpy.ndarray,Lis\n",
       ">                         t], y:Union[pandas.core.frame.DataFrame,numpy.ndarray,\n",
       ">                         List])\n",
       "\n",
       "Fit the TargetEncoder to X.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | Union[pd.DataFrame, np.ndarray, List] | The data to determine the categories of each feature. |\n",
       "| y | Union[pd.DataFrame, np.ndarray, List] | The associated target vector. |\n",
       "| **Returns** | **TargetEncoder** | **Fitted TargetEncoder.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rxavier/poniard/blob/master/poniard/preprocessing/categorical.py#L67){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TargetEncoder.fit\n",
       "\n",
       ">      TargetEncoder.fit\n",
       ">                         (X:Union[pandas.core.frame.DataFrame,numpy.ndarray,Lis\n",
       ">                         t], y:Union[pandas.core.frame.DataFrame,numpy.ndarray,\n",
       ">                         List])\n",
       "\n",
       "Fit the TargetEncoder to X.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | Union[pd.DataFrame, np.ndarray, List] | The data to determine the categories of each feature. |\n",
       "| y | Union[pd.DataFrame, np.ndarray, List] | The associated target vector. |\n",
       "| **Returns** | **TargetEncoder** | **Fitted TargetEncoder.** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(TargetEncoder.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9e7017",
   "metadata": {},
   "source": [
    "After fitting, the categories of each feature are held in the `categories_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88634fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rxavier/poniard/blob/master/poniard/preprocessing/categorical.py#L164){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TargetEncoder.transform\n",
       "\n",
       ">      TargetEncoder.transform\n",
       ">                               (X:Union[pandas.core.frame.DataFrame,numpy.ndarr\n",
       ">                               ay,List])\n",
       "\n",
       "Transform X using specified encoding scheme.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | Union[pd.DataFrame, np.ndarray, List] | Transformed input. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rxavier/poniard/blob/master/poniard/preprocessing/categorical.py#L164){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TargetEncoder.transform\n",
       "\n",
       ">      TargetEncoder.transform\n",
       ">                               (X:Union[pandas.core.frame.DataFrame,numpy.ndarr\n",
       ">                               ay,List])\n",
       "\n",
       "Transform X using specified encoding scheme.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | Union[pd.DataFrame, np.ndarray, List] | Transformed input. |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(TargetEncoder.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d65016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### TransformerMixin.fit_transform\n",
       "\n",
       ">      TransformerMixin.fit_transform (X, y=None, **fit_params)\n",
       "\n",
       "Fit to data, then transform it.\n",
       "\n",
       "Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
       "and returns a transformed version of `X`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | array-like of shape (n_samples, n_features) |  | Input samples. |\n",
       "| y | NoneType | None | Target values (None for unsupervised transformations). |\n",
       "| fit_params |  |  |  |\n",
       "| **Returns** | **ndarray array of shape (n_samples, n_features_new)** |  | **Transformed array.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### TransformerMixin.fit_transform\n",
       "\n",
       ">      TransformerMixin.fit_transform (X, y=None, **fit_params)\n",
       "\n",
       "Fit to data, then transform it.\n",
       "\n",
       "Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
       "and returns a transformed version of `X`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | array-like of shape (n_samples, n_features) |  | Input samples. |\n",
       "| y | NoneType | None | Target values (None for unsupervised transformations). |\n",
       "| fit_params |  |  |  |\n",
       "| **Returns** | **ndarray array of shape (n_samples, n_features_new)** |  | **Transformed array.** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(TargetEncoder.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b0659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1f6705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sex    status\n",
       "0  0.437500  0.416667\n",
       "1  0.250000  0.375000\n",
       "2  0.250000  0.416667\n",
       "3  0.464286  0.416667\n",
       "4  0.464286  0.375000\n",
       "5  0.464286  0.416667\n",
       "6  0.464286  0.416667\n",
       "7  0.464286  0.416667\n",
       "8  0.464286  0.416667\n",
       "9  0.437500  0.375000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "\n",
    "X = pd.DataFrame(\n",
    "    {\n",
    "        \"sex\": rng.choice([\"female\", \"male\", \"other\"], size=10),\n",
    "        \"status\": rng.choice(\n",
    "            [\"employed\", \"unemployed\", \"retired\", \"inactive\"], size=10\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "y = rng.choice([\"low\", \"high\"], size=10)\n",
    "\n",
    "encoder = TargetEncoder(task=\"classification\", handle_unknown=\"ignore\")\n",
    "pd.DataFrame(encoder.fit_transform(X, y), columns=encoder.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a9841a",
   "metadata": {},
   "source": [
    "In the case of a multiclass target, the encodings are computed separately for each label,\n",
    "meaning that each feature will be expanded to as many unique levels in the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603267e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex_high</th>\n",
       "      <th>sex_low</th>\n",
       "      <th>sex_mid</th>\n",
       "      <th>status_high</th>\n",
       "      <th>status_low</th>\n",
       "      <th>status_mid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex_high  sex_low   sex_mid  status_high  status_low  status_mid\n",
       "0  0.312500   0.3125  0.375000        0.250    0.458333    0.291667\n",
       "1  0.125000   0.6875  0.187500        0.125    0.562500    0.312500\n",
       "2  0.125000   0.6875  0.187500        0.250    0.458333    0.291667\n",
       "3  0.178571   0.5000  0.321429        0.250    0.458333    0.291667\n",
       "4  0.178571   0.5000  0.321429        0.125    0.562500    0.312500\n",
       "5  0.178571   0.5000  0.321429        0.250    0.458333    0.291667\n",
       "6  0.178571   0.5000  0.321429        0.250    0.458333    0.291667\n",
       "7  0.178571   0.5000  0.321429        0.250    0.458333    0.291667\n",
       "8  0.178571   0.5000  0.321429        0.250    0.458333    0.291667\n",
       "9  0.312500   0.3125  0.375000        0.125    0.562500    0.312500"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = rng.choice([\"low\", \"mid\", \"high\"], size=10)\n",
    "\n",
    "encoder = TargetEncoder(task=\"classification\", handle_unknown=\"ignore\")\n",
    "pd.DataFrame(encoder.fit_transform(X, y), columns=encoder.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac2ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poniard",
   "language": "python",
   "name": "poniard"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
